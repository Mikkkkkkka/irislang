<!-- Автоматически сконвертировано из PDF: План_разработки_языка_и_VM_AsyncJIT.pdf -->


# План разработки языка программирования и виртуальной машины на Kotlin Описание проекта: Небольшая команда из 4


разработчиков за 1–2 недели реализует минимальный язык программирования с
собственным байткодом и виртуальной машиной на Kotlin. Язык поддерживает
базовые конструкции (арифметику, if-else, циклы for / while, рекурсию через
функции), а среда исполнения обеспечивает автоматическое управление памятью
(сборщик мусора) и JIT-компиляцию для ускорения кода. Готовый продукт будет
представлен как утилита CLI, принимающая исходный код на новом языке и
выполняющая его. Для демонстрации работоспособности планируются три
тестовые программы: (1) рекурсивный расчёт факториала до 20, (2) сортировка
массива до 10 000 элементов, (3) генерация простых чисел до 100 000 (алгоритм
решето Эратосфена). Ниже приводится подробный технический план,
распределённый по ролям участников.
Разработчик языка и байткода
Роль и зона ответственности: Разработчик языка определяет синтаксис и
семантику нового языка, описывает все поддерживаемые конструкции,
разрабатывает формат байткода (набор инструкций виртуальной машины) и
реализует генерацию байткода из промежуточного представления. Код и
спецификации этой части хранятся в отдельном модуле/репозитории, например, в
подпапке language_spec проекта. Данный модуль будет содержать описание
грамматики, определение AST (Abstract Syntax Tree) для языка и структуру
байткода. Результаты работы этого разработчика являются входом для
разработчиков парсера и интерпретатора. Зависимости и интеграция: Разработчик
языка тесно взаимодействует с разработчиком парсера для согласования
грамматики и структуры AST, а также с разработчиком интерпретатора для
определения набора инструкций байткода. Контрольные точки синхронизации
включают утверждение спецификации языка и грамматики (начало разработки),
согласование формата байткода (перед реализацией интерпретатора) и
интеграцию генерации кода с парсером (середина проекта). Ежедневные задачи:
1. День 1: Сформировать черновую спецификацию языка. Описываются все
языковые возможности: типы данных (например, целые числа), литералы,
переменные, арифметические операции, синтаксис условных конструкций if-else,
циклов ( for, while ), а также способ определения функций для реализации
рекурсии (например, синтаксис func factorial(n) {... } ). Особое внимание уделяется
упрощённости — язык минималистичен, достаточный для демонстрационных
примеров. Также решается, будут ли переменные типизированы (скорее всего,
один тип int для простоты) и как представлять массивы (например, встроенный
тип массивов целых). На основе требований пишутся примеры кода на новом
языке (псевдокод) для задач факториала, сортировки и решета, чтобы убедиться,
что синтаксис покрывает нужные конструкции. Контрольная точка: команда
собирается для обсуждения черновой спецификации, корректирует синтаксис при
необходимости.



---


## Страница 2


2. День 2: Совместно с разработчиком парсера формализовать грамматику языка.
Определяется EBNF/BNF-грамматика: правила для выражений (с учётом
приоритетов операций), для операторов if / else (например, if (<условие>) <блок>
else <блок> ), для циклов while и for (упрощённый вариант цикла for, например for
i = 0 to N {... } или использование while как основной механизм), а также
синтаксис объявления функций и вызова функций. Если используется генератор
парсеров (ANTLR), подготавливается описание грамматики для него 1.
Параллельно определяется структура AST: список классов/узлов Kotlin,
описывающих конструкцию программы (узлы для литералов, бинарных операций,
условных операторов, циклов, узел функции с параметрами и телом, узел вызова
функции и т.д.). Результат дня: формальное описание грамматики (EBNF) и список
классов AST, согласованный с парсерщиком 2. 3. День 3: Разработать формат
байткода и набор инструкций виртуальной машины. Выбор падает на стековую
виртуальную машину для простоты реализации (все операции работают через
стек операндов) 3. Составляется перечень инструкций байткода, покрывающий
все языковые конструкции: 4. Арифметические операции: например, ADD, SUB,
MUL, DIV для сложения, вычитания, умножения, деления (двух верхних значений
на стеке). 5. Логические/сравнения: например, CMP_LT, CMP_EQ для сравнения
значений (результат – 1 или 0 на стеке) и др., чтобы реализовать условия. 6. Поток
управления: JMP addr (безусловный переход по адресу инструкции), JMP_IF addr
(условный переход, вынимает флаг с вершины стека и прыгает если он не ноль) –
для реализации if и циклов. 7. Работа с переменными: так как язык поддерживает
переменные и функции, вводятся инструкции для доступа к
локальным/глобальным переменным, например, LOAD varIndex / STORE varIndex
для загрузки/сохранения значения по индексу переменной (индексы переменных
могут относиться к текущему контексту выполнения – стеку вызовов). 8. Вызовы
функций: CALL funcIndex для вызова функции (сохранит адрес возврата, перейдёт
на указанный код функции) и RET для возврата из функции (восстанавливает
адрес возврата). Для передачи аргументов/возврата значения будет
использоваться стек: вызывающая сторона кладёт аргументы на стек перед CALL,
функция кладёт результат на стек перед RET. 9. Память и структуры: для
поддержки массивов придумываются инструкции ALLOC_ARR (выделить массив
заданной длины), LOAD_ARR и STORE_ARR (доступ к элементам массива по
индексу). Можно использовать простой подход: ALLOC_ARR вынимает со стека
размер, выделяет блок памяти в куче под массив и кладёт ссылку
(идентификатор) на массив обратно на стек; LOAD_ARR вынимает индекс и ссылку
массива, читает элемент и кладёт его на стек; STORE_ARR – вынимает индекс,
ссылку и новое значение, записывает значение в массив. 10. Прочие: PUSH_CONST
c для загрузки константного значения (например, числового литерала) на стек,
возможно POP чтобы убрать значение со стека (если нужно очистить).
Определяется числовой код (opcode) для каждой инструкции (например, 1 байт
для кода операции, за которым следуют операнды, если есть). Также описывается
формат представления байткода в памяти: например, массив байтов или слов, где
первая часть – таблица констант (константный пул), далее – код основных
функций. Выбран подход: пул констант (например, числовые литералы хранятся
один раз и обращение идёт по индексу) и разделение по функциям (каждая
функция имеет свой блок инструкций, при компиляции CALL funcIndex хранит
индекс/смещение целевой функции). Контрольная точка: команда созывает
встречу,



---


## Страница 3


разработчик языка предъявляет документ со спецификацией байткода и схемой
VM. Разработчик интерпретатора подтверждает реализуемость (например,
понимает как выполнять инструкции), разработчик парсера – как генерировать
эти инструкции из AST. 1. День 4: Реализовать генерацию байткода
(кодогенерацию) из AST. В кодовой базе создаётся класс/модуль CodeGenerator,
который принимает корневой AST программы (например, узел Program с перечнем
функций или операторов) и последовательно производит машинно-независимый
код (наш байткод). На этом этапе могут быть определены вспомогательные
структуры: например, таблица символов для отслеживания индексов переменных
(локальных переменных функции, глобальных, параметров функций) и таблица
функций для сопоставления имен функций с индексами/адресами. Задачи: 2.
Написать процедуры обхода AST (например, метод generate(Node) для каждого
типа узла). Для выражений генерация рекурсивная: сначала генерируется код для
подвыражений, затем инструкция операции. Для бинарного AdditionNode
генерируется код левого выражения, потом правого, затем инструкция ADD –
таким образом два операнда будут на вершине стека и ADD их заменит суммой. 3.
Для IfNode: генерируется код вычисления условия (оставляет 0/1 на стеке), затем
вставляется JMP_IF с адресом выхода из блока if (адрес пока как заглушка, его
нужно будет поправить позже), потом код блока then. Если есть блок else,
вставляется также JMP через этот блок else к концу if, и после then-блока адрес
первого JMP_IF корректируется на начало блока else, далее генерируется код
блока else и в конце else корректируется адрес JMP на точку после else-блока.
Таким образом реализуется разветвление. 4. Для циклов while: генерируется
метка начала цикла (сохраняем индекс начала в коде), код вычисления условия,
затем JMP_IF на выход (если условие ложное), потом тело цикла, затем инструкция
JMP обратно на начало цикла. Адрес JMP_IF корректируется на конец цикла (после
JMP ). Для цикла for (если поддерживается синтаксически) можно транслировать
его в эквивалентный while (инициализация перед циклом,
условие+тело+инкремент внутри). 5. Для CALL: кодогенератор должен
сгенерировать сначала код вычисления всех аргументов функции (они окажутся
на стеке), затем инструкцию CALL funcIndex. Здесь funcIndex – индекс функции,
определяемый при первой проходке списка функций (например, функции
пронумерованы в порядке объявления). Аналогично, в конце функции неявно
должен возвращаться результат: в функции можно определять явный ReturnNode,
при генерации которого эмитируется сохранение возвращаемого значения на
вершине стека (если не уже там) и RET. 6. Для работы с массивами: генерация
ALLOC_ARR после вычисления выражения длины, генерация LOAD_ARR / STORE_ARR
при встрече операций индексирования (тоже сначала вычисляются индекс и адрес
массива). В ходе реализации, для корректной расстановки адресов переходов
может использоваться двухпроходный подход: первый проход собирает
последовательность инструкций с фиктивными адресами, а затем заполняет
реальные адреса меток, или использовать динамическое построение с
возможностью назад исправлять операнд перехода, как описано выше. Результат
дня: прототип генератора кода, способный обработать простейшие конструкции
(например, выражения, простой if). Выполняются локальные тесты: вручную
конструируется маленький AST (например, выражение 2+3 ) и проверяется, что
генератор выдаёт ожидаемый байткод



---


## Страница 4


(например, PUSH_CONST 2; PUSH_CONST 3; ADD ). При необходимости генератор
дополняется логированием/печатью промежуточного байткода для отладки. 1.
День 5: Расширение генерации байткода на все конструкции языка. Добавляются
оставшиеся элементы: 2. Полная поддержка вложенных конструкций: if внутри
цикла, циклы внутри if и т.д. 3. Реализация генерации функций и рекурсии: при
генерации кода программы, сначала обрабатываются все объявления функций.
Можно сделать так: генератор проходит по AST, собирая таблицу функций (имя ->
индекс, а также AST тела функции). Затем основной "Program" разделяется: код
глобального уровня (если таковой разрешён, например, выполнение выражений на
уровне скрипта) и код функций. Для каждой функции генерируется свой блок
инструкций, сохраняется смещение начала функции. При генерации инструкции
CALL теперь заменяется имя функции на соответствующий индекс или адрес
входа. 4. Если в языке разрешены глобальные переменные или требуется
инициализация, можно сгенерировать специальную "main" функцию, содержащую
код глобального уровня, и виртуальная машина сначала вызывает её. 5. Обработка
ошибок: если AST содержит конструкции, которые не поддержаны генератором
(на этом этапе не должно остаться, т.к. всё предусмотрено), генератор выдаёт
понятное сообщение. Также, на случай семантических ошибок (например,
использование неинициализированной переменной), можно добавить проверки в
будущем, но в рамках 2 недель фокус на корректной трансляции корректного
кода. Результат: Генератор кода теперь умеет обрабатывать полноценные
функции, включая рекурсивные вызовы (например, AST факториала).
Производится тест: собирается AST для функции факториала и её вызова,
генератор выпускает байткод, и вручную проверяется последовательность
инструкций на соответствие логике (например, проверяется, что рекурсивный
CALL присутствует). При необходимости вносятся исправления. 1. День 6:
Интеграция с парсером и базовым интерпретатором. К этому дню разработчик
парсера должен предоставить возможность получить AST из исходного кода, а
разработчик интерпретатора – выполнить последовательность байткода.
Совместно интегрируем: после парсинга исходного файла (получения AST)
вызывается компонент генерации байткода, формируется структура байткода
(например, объект, содержащий список инструкций, таблицу констант, таблицу
функций). Затем этот байткод передаётся в виртуальную машину для исполнения.
Контрольная точка: первая сквозная проверка – выполняем простейшую
программу (например, программа, вычисляющая сумму двух чисел с выводом
результата). Разработчик языка вместе с коллегами отладки возможные
несоответствия: 2. Если парсер AST отличается от ожиданий генератора
(исправляют либо генератор, либо парсер – например, добавить явный узел для
return, если забыли). 3. Если интерпретатор ожидает другой формат байткода
(исправляют спецификацию или интерпретатор). Цель – к концу дня получить
работающий вертикальный срез: от исходного кода до выполнения на VM простого
сценария. 4. День 7: Добавление поддержки массивов и улучшение языка по
необходимости. На основе опыта первых тестов, язык может потребовать мелких
доработок. В частности, для демонстрационной задачи сортировки нужен способ
создать массив и заполнить его данными. Реализуется синтаксис массива
(например, литерал массива или функция для инициализации). В простейшем
случае можно предусмотреть встроенную функцию



---


## Страница 5


fillArray(n) для заполнения массива размером n случайными числами, либо
позволить программисту писать цикл заполнения. Разработчик языка определяет,
как именно демонстрация будет реализована. Например, можно решить, что
ввод/вывод не требуется (демо-программы просто выполняют вычисления), либо
добавить примитивную функцию print для вывода результатов в консоль (если
требуется увидеть вывод factorial, хотя можно и не выводить, просто проверять
корректность). Добавляются инструкции байткода для массивов (если не
полностью сделано ранее), и генератор кода обновляется: при обнаружении
обращения arr[index] или присваивания arr[index] = value генератор вместо
обычного поля генерирует последовательность: <код для вычисления адреса
массива> <код для индекса> <(код для значения)> и соответствующий LOAD_ARR
или STORE_ARR. Также решается, как представлять массив в AST (например, узел
IndexAccess или сделать вызов встроенной функции – в зависимости от реализации
парсером). После этого пишется тестовый код на разрабатываемом языке:
генерация массива, заполнение его, вызов сортировки (возможно, сортировка
реализуется в самом языке, например, пузырьком, либо для скорости можно
реализовать встроенную функцию сортировки, но лучше на языке для
демонстрации). Генерация байткода для этого кода и прогона через
интерпретатор выявит, все ли конструкции работают. Исправляются ошибки. 1.
День 8: Тестирование и отладка полноты языка на целевых примерах. Разработчик
языка совместно с командой пробует реализовать на новом языке три
демонстрационные задачи: 2. Факториал: пишется функция factorial(n) с
рекурсией, вызывается на n=20, проверяется результат (2432902008176640000
для 20!). Проверяем, что стек не переполняется, рекурсия работает (глубина 20).
3. Сортировка: реализуется, например, функция sort(array) (например,
пузырьковый метод или любой простой алгоритм) и код заполнения массива из 10k
элементов случайными значениями. После выполнения можно проверять, что
массив отсортирован. Здесь важно убедиться, что производительность
интерпретатора достаточна или потребуется JIT (вручную можно замерить время).
4. Решето Эратосфена: код генерирует булев массив размером 100k, отмечает
составные числа. После выполнения можно подсчитать количество полученных
простых (для n=100k ~9592 простых чисел). Проверяется корректность алгоритма.
Во время этих тестов выявляются узкие места и баги. Например, если
производительность интерпретатора на 100k элементов невысока, эти данные
послужат обоснованием для включения JIT-компиляции. Разработчик языка
фиксирует все обнаруженные проблемы, связанные с языком (недостающие
конструкции, неверная генерация в угловых случаях) и устраняет их. Контрольная
точка: внутренний релиз альфа-версии языка – все ключевые примеры
выражаются на языке и работают корректно на интерпретаторе (хотя и без
оптимизаций пока). 1. День 9: Оптимизация и шлифовка генерации кода. На этом
этапе, если время позволяет, в генератор можно внести простые оптимизации на
уровне байткода: 2. Устранение постоянных вычислений: константные выражения
(например, 2+3 ) можно сразу вычислить во время генерации и вместо серии PUSH
2; PUSH 3; ADD положить один PUSH 5. Это уменьшит размер кода и нагрузку на
VM 4. 3. Удаление мёртвого кода: если конструкция if имеет константное условие
(встретилось во время генерации), можно сразу выбрать нужную ветку. 4.
Локальные переменные vs стек: возможно, выделить в байткоде отдельные
инструкции для работы с локальными переменными по индексу вместо всегда
полагаться на стек,



---


## Страница 6


чтобы уменьшить глубину стека. (В нашем дизайне уже есть LOAD/STORE с
индексом – их использование есть форма оптимизации по сравнению с чисто
стековым подходом). Эти улучшения не являются обязательными, но могут быть
реализованы для учебной цели. Любые изменения согласуются с разработчиком
интерпретатора (чтобы он поддержал новые паттерны). Кроме оптимизаций,
разраб. языка актуализирует документацию: описывается финальный список
инструкций байткода, даётся BNF-грамматика языка, примеры кода. Возможно,
добавляется таблица соответствия конструкции языка -> последовательность
байткода (для наглядности и помощи JIT-разработчику). 1. День 10: Документация
и финальная проверка. Разработчик языка подготавливает техническое описание
языка – документ, включающий:
- Описание синтаксиса (грамматика, примеры
использования if, loops, функций).
- Семантика конструкций (что делают, как
работает вызов функции, области видимости переменных – например, переменные
функции локальны, рекурсия разрешена, глобальные/внешние переменные если
есть).
- Спецификация виртуальной машины и байткода: список всех инструкций,
формат представления (например, байт-код операции + 32-битный операнд для
адреса или константы, и т.д.). Можно привести кусочки байткода с пояснениями.
- Описание ограничений и допущений (например, размер стека, максимальное
число переменных или ограничение глубины рекурсии, если есть). Также
проводится контрольная синхронизация со всеми разработчиками: убедиться, что
документация соответствует реализованному; что все части (парсер,
интерпретатор, JIT) используют единые определения (имена инструкций,
кодировки). После этого разработчик языка помогает другим участникам в
оставшиеся дни по необходимости (например, написание дополнительных
тестовых программ, настройка CLI-интерфейса, проверка сообщений об ошибках
для пользователя). 2. Репозиторий/папка: language_spec (содержит описание
грамматики, классы AST, генератор байткода, документацию по языку). 3.
Зависимости: предоставляет разработчику парсера спецификацию грамматики и
формат AST; предоставляет интерпретатору формат и набор инструкций
байткода; получает AST- дерево от парсера в качестве входных данных. 4.
Ключевые контрольные точки: 5. Утверждение синтаксиса и грамматики языка
(день 2). 6. Утверждение формата байткода (день 3). 7. Интеграция парсер +
генерация + интерпретатор на простом примере (день 6). 8. Демонстрация работы
всех языковых конструкций на эталонных задачах (день 8). 9. Промежуточные
данные: Абстрактное синтаксическое дерево (AST) – выход парсера, вход для
генерации байткода 5. Байткод (последовательность инструкций + таблицы
констант/функций) – выход генерации, исполняемое представление для
интерпретатора/ JIT 6.
Разработчик парсера
Роль и зона ответственности: Разработчик парсера отвечает за реализацию
разбора исходного кода на новом языке. Он создает лексический и
синтаксический анализаторы, которые читают



---


## Страница 7


текст программы и строят корректное AST, соответствующее спецификации,
предоставленной разработчиком языка. Код этой части хранится в отдельном
модуле/папке, например parser, включающем грамматику (если используется
генератор) и исходники парсера. Парсер должен поддерживать все конструкции
языка и выдавать понятные ошибки синтаксиса. Также, при необходимости,
парсер может выполнять простую семантическую проверку (например,
обнаружение использования не объявленных ранее переменных или
некорректных типов, хотя для динамического языка это может быть
минимальным). AST, формируемый парсером, используется генератором байткода.
Зависимости и интеграция: Парсер опирается на спецификацию языка/грамматику
от разработчика языка. Он выдает AST, который потребляется модулем генерации
байткода. Точки синхронизации включают завершение разработки грамматики
(начало), интеграцию с кодогенерацией (середина проекта) и финальную отладку
с интерпретатором (после подключения генерации). Ежедневные задачи: 1. День
1: Подготовка инфраструктуры парсера. Выбор инструмента: можно реализовать
парсер вручную (рекурсивный спуск) или использовать генератор парсеров
(например, ANTLR). ANTLR предпочтителен для быстрого получения надежного
парсера: достаточно описать грамматику, и он сгенерирует лексер и парсер на
Kotlin/Java 1. Разработчик устанавливает окружение (например, подключает ANTLR
Kotlin Target или, если решено не использовать ANTLR, настраивает свой каркас).
Создается репозиторий/проект parser. Если используется ANTLR, добавляется
grammar-файл (e.g., MyLang.g4 ) с базовыми секциями. Если парсер пишется
вручную, закладываются необходимые классы: лексер (для разбиения строки на
токены) и парсер (навигация по списку токенов с применением правил
грамматики). В конце дня: минимальный каркас – при запуске парсера он может
прочитать пустой или тривиальный файл и не упасть, структура проекта понятна.
2. День 2: Разработка лексера и базовых правил грамматики. Лексер определяет
набор токенов: ключевые слова ( if, else, for, while, func и т.п.), идентификаторы,
числовые литералы, операторы ( +, -, *, /, ==, <, = для присваивания, скобки,
фигурные скобки для блоков и т.д.), символы конца инструкции (может быть; либо
конец строки). Если ANTLR, эти правила записываются в грамматике как
лексические правила 7. Далее прописываются первые синтаксические правила: 3.
Правило для программы (например, program: (functionDecl | statement)* EOF; –
программа состоит из списка функций или операторов на верхнем уровне). 4.
Правило для выражений (с учетом приоритетов: возможно использование
операторных предшествований в ANTLR или несколько правил: expr: expr ('+'|'-')
expr | expr ('*'|'/') expr | INT | IDENT |... ). 5. Правила для операторов: например,
statement: 'if' '(' expr ')' block ('else' block)? | 'while' '(' expr ')' block | 'for' '('... ')' block |
assignment | exprStmt | returnStmt | block. Здесь block представляет
последовательность операторов в { }. 6. Правило для объявления функции:
functionDecl: 'func' IDENT '(' paramList? ')' block. Разработчик парсера плотно
сотрудничает с разработчиком языка, чтобы убедиться, что грамматика
соответствует задуманному синтаксису. После написания основных правил,



---


## Страница 8


парсерщик запускает генерацию парсера (если ANTLR) или компилирует свой код,
устраняет синтаксические конфликты (например, левую рекурсию или
неоднозначности). Результат дня: черновая грамматика, способная разобрать
простые конструкции. Можно протестировать: написать элементарный входной
код (например, a = 1+2; ) и запустить парсер – удостовериться, что распознаётся
корректно (например, через отладочный вывод или отлов исключений). Любые
проблемы разбираются (ANTLR выдаст предупреждения о конфликтных правилах,
их поправить). 1. День 3: Построение Abstract Syntax Tree. Если используется
ANTLR, по умолчанию он построит parse tree – дерево разбора с множеством
технических узлов. Задача – преобразовать его в удобный AST, состоящий из
Kotlin-классов, определённых разработчиком языка. Парсерщик может
воспользоваться паттерном Visitor или Listener, который генерирует ANTLR:
проходя по parse tree, создавать экземпляры AST-классов и связывать их.
Например: 2. При входе в правило выражения expr создаётся соответствующий
узел AST: если обнаружен подправило сложения, создаётся BinaryOpNode(+,
leftExpr, rightExpr). 3. Правило if – на выходе формируется IfNode(condExpr,
thenBlock, elseBlock) где thenBlock и elseBlock – списки операторов AST. 4. Правило
функции – генерирует FunctionNode(name, params, bodyAST). 5. Идентификаторы
переменных и литералы – преобразуются в VarRefNode(name) и
IntLiteralNode(value) соответственно. Если парсер написан вручную, то во время
разбора сразу создаются AST-объекты (методы парсера возвращают AST-узлы).
Преимущество ANTLR – наличие автоматического лексера/ парсера; но AST всё
равно часто строят вручную для удобства 2. Разработчик реализует этот этап,
стараясь минимизировать зависимость от конкретных классов ANTLR (чтобы AST
был «чистым»). Результат: функции Visitor/Builder, возвращающие полностью
построенный AST программы. Проводятся тесты: входной код -> AST. Например, if
(1<2) x=3 else x=4 должен давать IfNode с вложенными узлами. Проверяется
несколько разных конструкций, сравнивается с ожиданиями. Исправляются
ошибки несоответствия (неправильно построенные узлы, пропущенные элементы
и т.п.). 1. День 4: Реализация остальных синтаксических конструкций и улучшение
обработки ошибок. Парсер дополняется правилами и AST-генерацией для
оставшихся элементов: 2. Цикл for: если синтаксис for отличается (например, for i
= 0; i < N; i = i + 1 {...} ), нужно правильно разобрать и отразить в AST (возможно,
как отдельный узел ForNode(init, condition, update, body) или преобразовать сразу в
эквивалент while). 3. Операции с массивами: определить синтаксис обращений к
элементам (например, arr[i] ). Добавить лексеру символ [ ], добавить в грамматику
выражений поддержку суффикса индексирования, чтобы ident '[' expr ']'
распознавался. AST-узел можно сделать IndexAccessNode(arrayExpr, indexExpr) для
чтения или присваивания. Также синтаксис создания массива: можно добавить
например конструкцию new IntArray(expr) или литерал типа [0,0,...] (но для
простоты, скорее new - конструкция). Это тоже добавить в грамматику и AST
(например, ArrayAllocNode(sizeExpr) ). 4. Возврат из функции: ввести ключевое
слово return и правило returnStmt: 'return' expr? ';'. В AST создать
ReturnNode(valueExpr) (valueExpr может быть null для функций без возвращаемого
значения).



---


## Страница 9


5. Прочие детали: убедиться, что блоки ( { } ) правильно обрабатываются (AST
узел Block со списком или просто список), что вложенные блоки (например, в if или
функциях) корректно формируются. Парсер начинает поддерживать весь спектр
языка. Проводится семантическая проверка на уровне парсера (базовая):
например, можно проверить, что каждая функция перед использованием
объявлена (или пометить вызовы, которые потом разрешатся). Если язык
статически типизирован (маловероятно для данного простого языка), то тут бы
происходила проверка типов. Скорее всего, язык динамически типизирован (все
числа), так что таких проверок минимум. Но обработка ошибок: нужно, чтобы при
синтаксической ошибке (неправильный код) парсер выдавал понятное сообщение.
ANTLR это частично делает сам, но можно настроить собственный ErrorListener для
вывода, или, если парсер ручной, добавить сообщения вроде "Ошибка: ожидался )
". Разработчик парсера проводит испытания: вводит намеренно ошибочные
конструкции (пропущенная скобка, неожиданный символ) и смотрит, сообщается
ли ошибка и где. Улучшает сообщения при необходимости. 1. День 5: Интеграция с
генерацией байткода. К этому дню парсер уже умеет строить AST, а разработчик
языка – генерировать по AST байткод. Нужно связать эти компоненты. Совместно с
разработчиком языка решается, как будет вызываться генерация: вероятно,
модуль парсера будет иметь метод parseProgram(String source): ProgramAST, а
модуль кодогенерации – метод generateBytecode(ProgramAST): BytecodeModule.
Разработчик парсера добавляет код вызова генератора (или предоставит AST
наружу, а уже наружный координатор вызовет генерацию). Обсуждаются детали
передачи данных: возможно, AST и байткод размещены в общем объектном
формате или используются DTO. Важно убедиться, что структура AST полностью
согласована с ожиданиями генератора. Например, генератор может ожидать, что
каждый ReturnNode присутствует явно в конце функции – парсер должен либо сам
добавить неявный возврат (если требуются) либо генератор учтёт отсутствие.
Таких нюансов много, поэтому разработчик парсера и языка проводят совместную
отладку на нескольких примерах: 2. Функция без явного return – должна ли
добавляться возврат нулевого значения? Решается единообразно. 3. Порядок
функций: если есть взаимные рекурсии, парсер AST может не переупорядочивать,
генератор должен справиться, имея таблицу имен. Проверяют, что имена функций
в AST уникальны, а вызовы содержат, например, имя или ссылку на FunctionNode (в
AST можно было сразу в узле вызова хранить ссылку на функцию; или пусть
хранится имя, а генератор сам свяжет). 4. Разметка узлов для переменных: парсер
может не знать про индексы переменных – это работа генератора/семантики. Но
важно, чтобы в AST было понятно, где объявление переменной, а где
использование. Можно, например, на уровне AST различать узел присваивания
AssignNode(varName, expr) и узел обращения VarRefNode(varName).
Семантическую проверку на объявление-до-использования в динамическом языке
можно упростить (выполнять на этапе исполнения), но лучше хотя бы для функций
гарантировать, что нет вызова неопределенной функции (парсер может проверить
наличие FunctionNode с таким именем). Результат дня: исходя из совместных
тестов, достигается полная совместимость: парсер -> AST -> байткод ->
интерпретатор. Как только цепочка начинает возвращать правильный результат
хотя



---


## Страница 10


бы для простого примера, можно считать задачу выполненной. Остаток дня –
резерв под исправление багов. 1. День 6: Тестирование парсера на сложных
примерах. Теперь, когда интеграция произошла, парсер прогоняется на всех
целевых программах: 2. Код факториала: проверяется, что парсер строит
корректный AST (с рекурсивной функцией). Если рекурсия хвостовая или нет, это
не важно для парсера, но важно убедиться, что глубина рекурсии не вызывает у
парсера проблем (не должна, 20 – маленькое). 3. Код сортировки 10k элементов:
тест скорее для парсера не сложный (один цикл, несколько вложенных, но не
огромный). Однако 10k – это размер данных, не кода, так что код не огромный.
Парсер здесь должен переваривать массивные литералы или конструирование,
если мы, например, позволим написать arr = new IntArray(10000). Это ок. Но можно
протестировать, например, на 100k (решето) – код: один цикл вложенный в другой
(до sqrt(100k) ~ 317), плюс несколько операторов. Объём кода всё ещё небольшой.
Тем не менее, стоит убедиться, что парсер способен справиться и с более крупным
скриптом (можно скопировать/сгенерировать какой-то крупный кусок). 4.
Проверяется, что время разбора не является узким местом (скорее всего нет,
объём кода мал). Если бы грамматика была неоднозначной или медленной
(backtracking), тут бы выявилось. ANTLR обычно эффективен. 5. Особое внимание
уделяется корректности разбора крайних случаев: пустой блок {}, пустая
программа (ничего – может быть не разрешено, но на всякий случай), возвращение
из середины функции, вложенные условные операторы. Парсер должен корректно
это отражать в AST. По итогам тестов исправляются обнаруженные
синтаксические ошибки или несоответствия AST. Например, могло выявиться, что
конструкция for не парсится как задумано – поправляют правило. Или что в
выражениях ассоциативность не та (например, a - b - c AST должен быть ((a - b) -
c), если получилось (a - (b - c)), нужно задать правильную левую ассоциативность в
грамматике). Такие вещи тщательно проверяются. 1. День 7: Улучшение
взаимодействия с пользователем через CLI. Поскольку интерфейс программы –
командная строка, следует продумать, как парсер будет использоваться: 2.
Вероятно, будет общий main.kt, который читает файл исходника, вызывает
парсер.
Разработчик парсера пишет удобный метод
parseFile(filename): AST и
обрабатывает исключения. Если возникает синтаксическая ошибка, бросается
собственное исключение с сообщением и позицией. Этот текст будет выведен
пользователю. Формат сообщения может быть: Error at line X: unexpected token...,
либо использовать формат ANTLR (у него есть RecognitionException с
координатами). 3. Добавление поддержки комментариев в языке: например, // до
конца строки, или / *... */. В лексере правила для этого можно добавить,
отправляя комментарии в отдельный канал (SKIP/WHITESPACE). 4. Поддержка
кириллицы не требуется (язык, вероятно, ориентирован на англ. ключевые слова),
но убедиться, что encoding входного файла UTF-8. 5. Опционально: реализовать
режим, где парсер по запросу выдаёт отладочное представление AST (например,
опция командной строки --print-ast для вывода дерева). Это может помочь при
отладке и демонстрации. Если решено, парсерщик добавляет соответствующую
функциональность (например, простой обход AST и печать узлов с отступами).



---


## Страница 11


Результат: Пользовательский опыт отточен – при запуске CLI с файлом
синтаксические ошибки понятны, без молчаливых сбоев. 1. День 8: Финальная
отладка и подготовка документации парсера. После подключения JIT и GC (к этому
дню, вероятно, коллеги уже интегрируют), проводится полный цикл тестирования
всей системы, но с фокусом на парсере: 2. Проверка, что любая программа,
корректно выполняющаяся, сначала правильно парсится. Если на этапе
исполнения находится баг, удостовериться, что он не из-за парсера (например,
неверно построен AST). 3. Парсерщик просматривает логи/трассировки
JIT/интерпретатора, чтобы убедиться: они выполняют то, что парсер отдал. Если,
например, интерпретатор падает на какой-то конструкции, проверяется, а
правильно ли парсер ее представил. Иногда баг может крыться в AST (например,
потерянный узел). 4. Проверяются edge-case: recursion – парсер уже проверял, но
особенно: взаимная рекурсия (func A вызывает B, а B вызывает A). Если такое есть
среди демо (вряд ли), но можно сделать пробный код. Парсер должен это
позволять (он позволил, т.к. собирает все функции). 5. Проверка глубоко
вложенных выражений или блоков (например, if внутри if внутри if...).
Ограничений на вложенность особых нет, кроме стека выполнения парсера (ANTLR
by default поддерживает достаточно). Затем документация: описывается
грамматика (можно приложить.g4 файл или его эквивалент как есть),
указываются грамматические правила с пояснениями. В документе от
разработчика языка может быть использована, но здесь парсерщик может
дополнить: например, разъяснить, что грамматика LL(*) без левой рекурсии (если
про ANTLR), что использован такой-то подход для разрешения приоритетов. Также
указывается, что парсер генерируется ANTLR (если это так) – значит, потребуется
включить шаг генерации в сборку (Gradle плагин). Если парсер свой, описать
архитектуру (лексер+рекурсивный спуск). Результат дня: парсер стабилен,
документирован, готов к релизу. 1. День 9: Резервирование под поддержку
оптимизаций и изменение требований. Возможно, на этом этапе коллеги,
занимающиеся JIT, поймут, что для упрощения JIT- компиляции лучше слегка
скорректировать грамматику или AST. Например, JIT-у проще, если все выражения
имеют явные узлы, или если циклы for уже переведены в while на этапе парсинга.
Разработчик парсера обсуждает такие возможности: 2. Можно на этапе парсинга
или сразу после (в AST) делать десугаринг некоторых конструкций. Например,
распустить for (init; cond; step) {body} в эквивалент: init; while(cond) { body; step; }.
Это можно сделать либо прямо в парсере (AST для for сразу строить как AST для
while), либо отдельным проходом трансформации AST. Такой подход уменьшает
объем работы генератора и JIT, так как все циклы по факту while. Если решат,
парсерщик это реализует. 3. Другая трансформация: свёртка констант (но обычно
это работа генератора). Можно не дублировать. 4. Участие в оптимизациях не
основная задача парсерщика, но он может помочь, например, реализовать
AST-анализ: пройтись по AST и пометить, какие функции являются кандидатами
для JIT (например, горячие циклы). Однако, в рамках 2 недель, вероятно, стратегия
JIT будет проще (компилировать всё или по факту выполнения).



---


## Страница 12


Парсерщик также проводит финальную ревизию кода: рефакторит длинные
методы, добавляет комментарии, чистит отладочный вывод. Убеждается, что
покрыты все конструкты (нет ли в грамматике правил, которые остались
неиспользованными или неоттестированными). 1. День 10: Завершение работы
над парсером. Все участки интеграции проверены. В репозиторий parser
добавляются примеры входных программ и, возможно, юнит-тесты для парсера:
т.е. автоматические тесты, которые берут строку исходника и проверяют, что
полученный AST соответствует ожидаемому (можно просто проверять не null и
типы узлов, или более детально). Такие тесты пригодятся при будущем изменении
языка. Парсерщик также подготавливает README по запуску парсера (если он
отдельно) и описывает, как интегрирован парсер в главный CLI (скорее всего,
единый CLI вызывает его). Проверяется, что сборка проекта генерирует парсер
(если ANTLR) – на CI/локально. Последние часы – поддержка коллег: например,
проверка, что сборщик мусора не требует изменений в AST (маловероятно, GC
работает на уровне выполнения). 2. Репозиторий/папка: parser (содержит
описание грамматики, сгенерированный лексер/ парсер или ручной парсер, код
построения AST, тесты). 3. Зависимости: использует спецификацию языка от Role1;
отдает AST на вход генератору байткода; зависит от AST-классов, определённых в
модуле языка (или дублирует их, но лучше переиспользовать общие модели). 4.
Ключевые контрольные точки: 5. Завершение грамматики и лексера (день 2–3). 6.
Построение AST и согласование его с разработчиком языка (день 3–4). 7.
Интеграция парсера с генерацией и выполнение простого сценария (день 6). 8.
Парсинг всех демо-программ без ошибок (день 8). 9. Промежуточные данные:
Parse Tree (внутреннее представление ANTLR) – используется кратко для
построения AST 2. Основной выход – AST (иерархия узлов в памяти), который
затем кодогенерируется. AST выступает универсальным интерфейсом между
парсером и последующими фазами, что соответствует классической схеме
компиляции 5.
Разработчик интерпретатора и виртуальной
машины
Роль и зона ответственности: Разработчик интерпретатора реализует исполнение
сгенерированного байткода на виртуальной машине. Он создает модель
виртуальной машины (стековый интерпретатор) в Kotlin: основные структуры (стек
операндов, heap для объектов, таблица глобальных/локальных переменных,
механизм вызова функций) и цикл исполнения инструкций (fetch-decode-execute).
Также этот разработчик участвует в реализации подсистемы управления памятью:
выделение объектов в куче, взаимодействие со сборщиком мусора (который
разрабатывается Role4). Работа хранится в модуле/папке vm (или interpreter ).
Результатом является функция (или класс) VM, которую можно вызвать, передав
ей байткод, и она выполнит программу, обеспечивая корректность согласно
семантике языка. Зависимости и интеграция: Интерпретатор опирается на формат
байткода, предоставленный Role1 (конкретные коды инструкций и их поведение).
Он получает сгенерированный байткод от связки парсер+кодогенератор. В то же
время, интерпретатор должен обеспечивать hooks для JIT- компилятора и GC:
например, при выполнении часто вызываемой функции – вызвать JIT, или при
исчерпании памяти – инициировать сборку мусора. Синхронизация обязательна на
этапе



---


## Страница 13


финализации формата байткода (чтобы реализовать все инструкции) и при
интеграции JIT (решить, как переключаться между интерпретируемым и
скомпилированным кодом). Ежедневные задачи: 1. День 1: Проектирование
архитектуры виртуальной машины. Разработчик интерпретатора на основе
спецификации байткода (от Role1) решает организационные детали VM: 2. Стек
операций: Выбирается размер (например, фиксированный массив на несколько
тысяч элементов, либо динамический). Для простоты, скажем, 10000 элементов int
– достаточно для наших задач, или делаем динамически расширяемый. 3. Модель
исполнения функций: Решается, как хранить контекст выполнения. Один из
вариантов – использовать тот же стек для операндов и для локальных
переменных/ фреймов. Например, как в JVM: разделить стек на фреймы, каждый
содержит локальные переменные и операнды текущей функции. При вызове
функции создаётся новый фрейм. Для упрощения можно использовать два стека:
один для операндов, другой – для адресов возврата и базовых индексов (call
stack). Выбирается подход: например, отдельный стек вызовов (java style) или
минималистично внедрить в операндный стек. 4. Представление байткода:
Решается, как хранить полученный байткод в памяти Kotlin. Вероятный вариант:
класс BytecodeModule с полями: constPool: List (для констант), functions: List (где
FunctionCode содержит массив инструкций этого метода). Каждая инструкция
может быть представлена как Int или Byte + операнды. Например, можно
кодировать одну инструкцию как 1 байт опкода + несколько байтов операндов, но
для удобства парсинга в Kotlin можно представить все как Int-массив, где операнд
идет отдельным элементом. 5. Инициализация VM: Должен быть метод, который
принимает объект байткода и готовит VM к запуску. Например, загружает
constPool, нулевые глобальные переменные, устанавливает начальный указатель
команд на entry point (скажем, если есть специальная функция "main" – ее
вызвать, или выполнять топ-левел код). 6. CLI исполнение: В целом
CLI-приложение будет вызывать VM.run(). Здесь же планируется, как сделать
вывод результатов (если язык предоставляет print, то интерпретатор может
обработать специальную инструкцию или встроенную функцию). Разработчик
создает скелет класса VirtualMachine с полями (стек, куча, др.) и методами run()
или executeFunction(funcIndex) и закладывает placeholders для инструкций. К концу
дня: имеется каркас VM, готовый к заполнению, и документ, описывающий
основные решения (стековая модель, разделение памяти), согласованный с
командой. Например, все соглашаются, что VM – стековая 8, глубина рекурсии
ограничена размером стека, многопоточности не будет (один поток исполняет
код). 1. День 2: Реализация основной петли интерпретатора и простейших
инструкций. Пишется метод run() виртуальной машины, выполняющий цикл: while
(true) {
val opcode = fetchNextByte()
when (opcode) { ADD -> { val b = pop(); val a = pop(); push(a + b) } SUB -> {... }...
JMP -> { val addr = fetchOperand(); pc = addr; continue }... HALT -> break



---


## Страница 14


} } Здесь fetchNextByte() читает следующий байт (или Int) из массива инструкций
текущей функции (по указателю pc – program counter). fetchOperand() читает
следующий единица данных (адрес или индекс) из инструкции. Начинается с
реализации базовых арифметических инструкций: ADD, SUB, MUL, DIV – берут два
значения из стека, выполняют операцию, результат кладут обратно. Добавляются
PUSH_CONST c: берет следующий операнд (индекс константы) и кладет значение
из constPool на стек. Эти операции тестируются первыми, поскольку просты.
Реализуется также минимальная инфраструктура работы со стеком: методы
push(int), pop(): int. Возможно, в целях отладки делают проверку на
переполнение/опустошение стека (например, если pop вызывается на пустом –
ошибка выполнения). Тестирование: Разработчик пишет небольшой байткод
вручную, например: constPool=[10,20], code: PUSH_CONST 0; PUSH_CONST 1; ADD;
HALT. Ожидается на вершине стека 30. Запускает VM.run() – проверяет результат.
Параллельно, если генератор кода (Role1) уже что-то умеет, можно взять его
вывод на простой выражение и попробовать исполнить. Пока функции, ветвления
можно не трогать. Главное – убедиться, что цикл while корректно итерирует, pc
правильно двигается (например, увеличивается на 1 + размер операндов). 1. День
3: Реализация управления потоком: прыжки и условные переходы. Добавляются
инструкции: 2. JMP addr: как частично выше – читает адрес (можно делать адрес
относительным или абсолютным, но проще абсолютный индекс в массиве
инструкций функции), устанавливает pc на это значение. Нужно учесть, что после
каждой инструкции pc обычно указывает на следующую, но при прыжке мы
переписываем pc. Возможно, придется -1 где-то, если цикл while инкремента pc
уже сделал. Но проще: когда считываем opcode, pc уже указывает на следующий
байт, так что для JMP делаем pc = addr (addr либо прямо хранится, либо
рассчитывается как текущий pc + offset ). 3. JMP_IF addr: условный: вытаскивает
вершину стека; если не 0 – прыгает на адрес, иначе продолжает. (Реализация: val
cond = pop(); if(cond!= 0) pc = addr ). 4. Опционально, JMP_IF_FALSE может быть, но
можно обойтись одним, просто генерируя противоположное условие. 5. CALL
funcIndex: наиболее сложный. Для вызова функции нам нужно: получить индекс
функции (операнд), сохранить текущий контекст (адрес возврата и, возможно,
текущий базовый указатель стека), затем перейти на начало кода вызываемой
функции.
- Реализация: можно иметь стек вызовов (List) и стек баз (List) или один
стек структур Frame. Проще: завести класс Frame { val returnAddr; val localsBase } и
стек callStack. При CALL:
- Поместить в callStack новый Frame(returnAddr =
текущий pc, base = текущая база локальных переменных).
- Установить текущую
функцию = funcIndex (то есть переключить контекст инструкций на другой
массив). Можно хранить текущий индекс функции, а также массив инструкций в
исполнении.
- Установить pc = 0 (или куда указывает начало функции). Также,
возможно, скорректировать базу локальных переменных: если локальные
переменные адресуются по индексу от начала фрейма, запомнить текущую
позицию в общем операндном стеке как новую базу (например, base = stack.size -
nargs, если аргументы уже лежат).



---


## Страница 15


- Передача аргументов: Тут решается, как передавать: у нас аргументы уже на
стеке (генератор кладёт их перед CALL). Можно считать, что в момент входа в
функцию они находятся на вершине стека. Локальные переменные функции
(включая параметры) будут храниться также в стековом пространстве. Например,
можно оговорить: сразу после входа в функцию на вершине стека лежит
последний аргумент, ниже предыдущий и т.д. Функции знает сколько параметров,
но интерпретатору даже не нужно – просто будет обращаться к ним через LOAD
varIndex / STORE varIndex относительно base. 6. RET: возврат из функции. Нужно: 1.
Взять возвращаемое значение (можно по соглашению считать, что функция
оставляет его на вершине стека). 2. Очистить стек фрейма функции: например,
удалить локальные переменные и аргументы с операндного стека, кроме
оставленного результата. Если base хранился, то можно попросту обрезать стек
до положения base (это уберёт все локальные). 3. Поместить результат (если есть)
обратно на вершину стека (он мог быть там – может нужно сохранить заранее). 4.
Восстановить предыдущий Frame из callStack: взять returnAddr, поставить его в pc,
восстановить текущий контекст функции (указатель на код предыдущей функции,
base = base предыдущей). 5. Продолжить цикл. 7. HALT или эквивалент: возможно,
будет полезна инструкция завершения программы (например, интерпретатор
выходит из run()). Если реализуем top-level код, то выход из последней функции
можно трактовать как halt. Разработчик реализует CALL/RET осторожно, поскольку
легко ошибиться. Пишутся тесты: - Простейшая функция без параметров,
возвращающая константу: сделать байткод: constPool=[5], Function0: PUSH_CONST
0; RET, main: CALL 0; HALT. Ожидаем, что после выполнения в стеке останется 5.
Отладка покажет, что callStack корректно пушится/попится. - Тест с параметрами:
функция sum(a,b) = a+b. Байткод: Function0: LOAD 0; LOAD 1; ADD; RET. Main:
PUSH_CONST 10; PUSH_CONST 20; CALL 0; HALT. Ожидается 30. Если LOAD/STORE
ещё не реализованы, можно симулировать (но надо реализовать). Проверяется,
что CALL правильно настроил base: например, LOAD 0 внутри функции должен
взять первый аргумент. Для этого, скорее всего, внутри интерпретатора LOAD
index реализуют как stack[base + index] (где base – начало текущего фрейма в
операндном стеке). - Рекурсия: для уверенности, можно протестировать factorial(3)
руками: функция fact(n): if n<=1 return 1 else return n*fact(n-1). Пишется байткод,
прогоняется. Ожидается 6. Это серьёзно проверит CALL, т.к. вложенные вызовы.
Контрольная точка: Теперь интерпретатор поддерживает управление потоком и
вызовы – фактически, способен выполнить произвольную алгоритмическую
логику. Команда может впервые полностью исполнить программу факториала или
простой рекурсивной функции на интерпретаторе. Если что-то не работает
(например, глубина стека или неправильная адресация), эти баги устраняются. 1.
День 4: Управление кучей и памятью, подготовка к сборщику мусора. В языке
появляются динамические объекты – массивы (и потенциально строки, но в
требованиях не указано, можно ограничиться массивами). Интерпретатор должен
предоставлять кучу (heap) для хранения этих объектов, т.к. стек хранит только
примитивы (ints) и, возможно, ссылки на объекты. Задачи дня: 2. Решить, как
представлять объект "массив" в реализации. Можно, например, использовать
обычные Kotlin массивы IntArray внутри VM. То есть, при ALLOC_ARR(n) – просто



---


## Страница 16


выполнять val arr = IntArray(n) в Kotlin и сохранять в какую-то таблицу объектов,
возвращать индекс или reference. Однако, чтобы потом наш сборщик мусора
контролировал их, можно хранить не напрямую IntArray, а оболочку HeapObject со
служебной информацией (например, флаг маркировки, ссылка на реальные
данные). 3. Например, завести class HeapObject(val type: ObjectType, val data: Any,
var marked: Boolean) и heap: MutableList в VM. При ALLOC_ARR: создается
HeapObject(ObjectType.ARRAY, IntArray(n), marked=false), кладётся в heap список, и
возвращается индекс этого объекта в списке (или какой-то хендл). Этот индекс –
адрес объекта – можно трактовать как integer reference, который кладётся на стек
в нашем языке. То есть, на языке, работающем поверх VM, переменная массива
будет хранить не сам массив, а идентификатор (индекс в куче). 4. Реализовать
инструкцию ALLOC_ARR: достает со стека размер, создаёт объект, возвращает
reference (индекс). LOAD_ARR: достает индекс объекта (ref) и индекс элемента;
проверяет валидность (ref в пределах, элемент в границах массива), получает
объект из heap[ref], извлекает из его data нужный элемент и кладёт на стек.
STORE_ARR: аналогично, только записывает значение. 5. Аналогично можно
предусмотреть (на будущее) объекты других типов, но пока только массивы. 6.
Дополнительно по памяти: если будет ввод/вывод или строки, можно либо не
реализовывать, либо тоже хранить строки как объекты. После реализации,
протестировать: - Простейший сценарий: arr = new IntArray(3); arr[0]=5; x = arr[0]; –
выполнить на уровне байткода. Вручную можно: ALLOC_ARR 3 -> вернет ref
(скажем, 0); PUSH_CONST 5; PUSH_CONST 0; PUSH_CONST ref; STORE_ARR;
PUSH_CONST 0; PUSH_CONST ref; LOAD_ARR -> результат на стеке. Проверить, что
получается 5. - Интеграция с кодогенератором: убедиться, что Role1 генерирует
именно такую последовательность для arr[i]=... и...=arr[i]. - Многократные
выделения: написать байткод, который в цикле 100 раз делает ALLOC_ARR(10).
Пока GC не реализован, это потенциально растёт heap список. Но это нормально,
мы накапливаем. Позже GC будет чистить. Важный шаг: Начать интеграцию со
сборщиком мусора. Совместно с разработчиком GC обсуждается протокол: - Когда
вызывать GC? (например, если heap.size превышает определённый лимит, или
каждые N аллокаций). - Как пометить объекты? (в HeapObject есть поле marked ). -
Какие корни GC должен смотреть? (глобальные переменные, стек операндов, стек
вызовов). Интерпретатор готов предоставить эту информацию: например, метод
getRoots() возвращает все объектные ссылки на стеке и в глобалах. - На время
работы GC интерпретатор, вероятно, должен приостановить исполнение. Но у нас
однопоточно, можно просто вызвать функцию collectGarbage() в подходящий
момент. - Пока GC не готов, интерпретатор может добавить простой счётчик
аллокаций: например, каждый ALLOC_ARR увеличивает allocCount, и если
allocCount mod 50 == 0, вызывается (пока пустой) GC. Позже разработчик GC
заполнит функцию. - Эти детали определяются сейчас, чтобы впоследствии легко
вставить GC. 1. День 5: Реализация оставшихся инструкций и начальная
интеграция сборщика. К этому дню должны быть покрыты все инструкции,
задуманные разработчиком языка в спецификации. Нужно проверить, ничего ли
не упущено: 2. LOAD varIndex / STORE varIndex: хотя ранее, при реализации
функций, мы концептуально их учли, код мог ещё не быть написан. Теперь
реализуется: LOAD idx – берет значение из операндного стека по индексу
currentFrame.base + idx и пушит его (то есть дублирует значение переменной на
вершину стека). STORE idx – снимает вершину стека и записывает по адресу
base+idx. Здесь важно: base – индекс начала локальных



---


## Страница 17


переменных текущей функции на общем стеке. Base устанавливался при CALL.
Этот механизм тестировался с sum() выше, теперь оформить окончательно. 3.
CMP_EQ, CMP_LT, CMP_GT, etc.: для условий. Например, CMP_LT – вынимает два
верхних значения, сравнивает (a, >= можно комбинировать (или генератор будет
генерировать обратные условные переходы). 4. Работа с глобальными
переменными: если язык поддерживает глобальные, нужен механизм. Можно
поступить просто: все глобальные переменные хранятся в словаре globals:
MutableMap (или по индексу). При загрузке программы, генератор может выделить
массив глобальных с известными индексами. Если так, нужны инструкции
LOAD_GLOBAL index / STORE_GLOBAL index. Если глобальных немного (например,
константы, или никаких), можно обойтись. Но, например, если топ-левел код
имеет переменные, надо как-то хранить. Пусть будет подобно локальным, только
хранится в globals массиве внутри VM. Тогда реализовать эти инструкции
аналогично, только берут из глобального хранилища. 5. Ввод/вывод: неявно, но,
возможно, нужно реализовать примитив печати. Если решили иметь print как
встроенную функцию, можно в парсере распознавать print(expr) и генерировать
специальный opcode PRINT. Тогда здесь сделать: PRINT – pop значение и println его
через Kotlin. Это не строго требовалось, но полезно для демонстрации factorial
output. 6. HALT/EXIT: добавить для явного завершения (если нужно, иначе выход по
концам функций и main). После дописывания всех инструкций, выполняется
полный прогон на эталонных программах без JIT и GC: - Факториал(20) – проверить
правильность результата. 20! влазит в 64-бит (который мы используем?), кстати
20! = 2.43e18, что превышает 2^31, так что int32 не хватит. Нужно решить: мы
работаем с Kotlin Int (32-bit) – он переполнится. Возможно, стоило указать 64-bit
(Kotlin Long ). Да, лучше с самого начала определиться: использовать 64-битные
целые для безопасности. Исправим: стек операндов Long, arithmetic op uses Long.
Тогда 20! = 2432902008176640000 помещается в 63-бит. Это граничный случай, но
важный для корректности демо. - Сортировка 10k – выполнить сортировку
(алгоритм написан на нашем языке). Если это пузырьковая сортировка, 10k
элементов – 50 миллион операций сравнения/присваивания, на чистом
интерпретаторе может быть очень медленно. Возможно, имеет смысл сократить
до, скажем, 1000 для демо, но заявлено 10000. Без JIT, скорее всего, будет
секундное измеримое время (зависит от оптимизации Kotlin VM, но у нас
интерпретатор – чистый цикл on top). В любом случае, важно, что он правильно
работает (можно не ждать полного выполнения, или если слишком долго, убить). -
Решето 100k – здесь массив 100k boolean (0/1) – 100k, алгоритм ~ O(n log log n) ~
100k * some factor, должно быть быстрее сортировки 10k^2, так что, может, ок.
Проверяется корректность (число простых). Если производительность совсем
плохая, это ожидаемо – как раз для этого JIT. Но функционально интерпретатор
должен все отработать. Если где-то происходит OutOfMemory (например, много
объектов, а GC ещё не включен), можно временно увеличить heap limit или
вручную вызывать GC (который еще не реализован). Но вероятно, эти программы
не создают огромного количества объектов (сортировка – 1 массив 10k, решето – 1
массив 100k, factorial – рекурсия 20 глубины, не проблемы). Сборщик мусора: к
концу дня возможно появляется первая реализация от Role4. Интерпретатор
разработчик интегрирует её вызов. Например, если договорено, что GC
вызывается когда
heap.size > 1000, он вставляет проверку после каждой ALLOC_ARR:



---


## Страница 18


heap.add(obj)
if(heap.size > 1000) GC.collect()
где GC.collect() – метод, предоставленный JIT/GC разработчиком. Надо передать
ему корневые ссылки: предоставляет, например, GC.setRoots(stack, callStack,
globals) или
GC.collect(heap, roots) – интерфейс согласуют. Пока, если GC не готов, можно вызывать
пустышку. 1. День 6: Интеграция с JIT-компиляцией (начало). Разработчик
интерпретатора начинает совместную работу с JIT-разработчиком: 2. Обсуждают
стратегию включения JIT: Будем ли мы компилировать функции на лету при
первом вызове (baseline JIT) или по счетчику (профилирующий). Для простоты
выбирается: при первом вызове функции компилировать её в машинный код и в
дальнейшем вызывать машинный код вместо интерпретируемого 9. Это упростит
реализацию (не нужен сложный профилировщик). В особо крупных циклах внутри
функции JIT тоже поможет, так что ок. 3. Механизм: интерпретатор при
выполнении инструкции CALL funcIndex будет проверять: скомпилирован ли уже
эта функция? Можно иметь массив/таблицу compiledFunctions параллельно
functions. Если entry присутствует, то вместо обычного процесса создания фрейма
и перехода в интерпретируемый код – вызывается скомпилированная функция
напрямую. Например:
if(jitCompiled[funcIndex]!= null) {
// подготовить аргументы, вызвать скомпилированную функцию
val result = jitCompiled[funcIndex].call(args...)
push(result) } else {
// обычный интерпретируемый вызов...
// и возможно после возврата, пометить, что можно скомпилировать
(например, счетчик вызовов++) } 4. Для этого интерпретатор предоставляет
JIT-модулю возможность скомпилировать функцию: скажем, при инициализации,
JIT-разработчик регистрирует callback: VM.registerJIT(jitCompiler). Тогда при первом
вызове CALL (или заранее) VM будет вызывать jitCompiler.compile(funcIndex)
который вернет исполняемый объект (например, интерфейс с методом). В
Kotlin/Java вызвать скомпилированный машинный код напрямую не тривиально,
скорее всего JIT-разработчик будет генерировать java.lang.reflect.Method или
функциональный интерфейс через Unsafe. Мы решаем интерфейс: пусть
jitCompiled[funcIndex] хранит kotlin функтор (LongArray)->Long или некий
CompiledFunction с методом execute(VM). Первый вариант: compile выдает lambda,
которая, зная о VM (доступ к ее стеку/куче), выполняет код. Это, однако, почти то
же самое, что интерпретатор, но может использовать JVM JIT если lambda
достаточно big? Альтернатива – генерировать нативный код и вызывать через JNI.
5. Вероятно, JIT-разработчик предложит конкретный способ (см. их план).
Интерпретатор должен его поддержать. Например, если JIT делает машинный код,
то он предоставит функцию pointer. В Java вызвать pointer можно через JNI native
stub или sun.misc.Unsafe



---


## Страница 19


НОВОЕ: Асинхронный JIT при CALL
Добавляем режим асинхронной компиляции: VM не блокируется на compile(), а
продолжает интерпретировать, пока JIT генерирует код в фоне.
Состояние функции: NOT_COMPILED -> COMPILING -> READY (или FAILED).
При CALL:
- READY: выполняем compiled;
- COMPILING: выполняем интерпретатором (fallback);
- NOT_COMPILED: ставим задачу на компиляцию и сразу fallback;
- FAILED: всегда fallback.
Реализация: корутины + Dispatchers.Default (CPU-bound), дедупликация
compile-once через ConcurrentHashMap/AtomicReference.



---


## Страница 20


( allocateMemory + invoke hack). В рамках Kotlin возможно использование
MethodHandle на native memory. Это сложно, но можно. 6. Пока, в упрощенном
плане: интерпретатор предоставляет API:
- fun getFunctionBytecode(funcIndex):
ByteArray – чтобы JIT мог получить байткод функции.
- fun
installCompiledFunction(funcIndex, CompiledFunc func) – чтобы JIT поставил
скомпилированную версию.
- Для вызова compiled: как выше, в CALL. Разработчик
интерпретатора в коде CALL реализует этот механизм: - Если функция не
скомпилирована: решает, компилировать ли сейчас. В baseline подходе – да, сразу.
Тогда вызывает jitCompiler.compile(funcIndex). (Либо можно сделать "лениво":
сначала интерпретировать 1 раз, а при втором – скомпилить. Но можем сразу). -
Получает объект (или pointer) скомпилированной функции, сохраняет в jitCompiled. - Далее выполнение: может сразу же выполнить эту функцию? Но тогда нужно
как-то управлять переходом. Один подход: вместо интерпретатора, просто
вызываем функцию, она сама всё сделает и вернёт результат. Тогда
интерпретатору надо: достать аргументы со стека, передать их, получить возврат.
Однако, скомпилированная функция, если она использует VM-структуры
(например, манипулирует стеком), может сама обращаться. Но лучше пусть она
действует автономно, используя только переданные аргументы. Но она может
иметь внутри вызовы других функций… - Возможно, решение: скомпилированные
функции не вызывают интерпретируемые – компилируем все (рекурсивно).
Например, при компиляции функции, если она вызывает другую, тоже
скомпилировать. Это baseline compiler behavior (наподобие AOT). Но за 2 недели,
реалистично – компилировать on-demand. Тогда, если compiled функция вызывает
неcompiled, придётся либо вызывать интерпретатор из нее (сложно), либо тоже
компилить. Можно упростить: наши демо- программы – возможно, без взаимных
сложных вызовов: factorial – рекурсивна (мы скомпилируем factorial, она вызывает
сама себя -> может вызвать либо интерпретируемую factorial -> infinite recursion
mixing). Лучше: при JIT-компиляции factorial, либо inline рекурсию (сложно), либо
treat call to itself as call to compiled version if available (which it is currently compiling –
self-call tricky). Simpler: allow compiled code to call back into VM for any call (like how
LuaJIT might do if not all compiled). But that requires writing bridging stubs.
- Чтобы not
overcomplicate, decide: compile all user functions at startup. Team might choose that
given few functions, just compile everything once. That simplifies call mechanism: no
mixed- mode calls, either everything in interpreter or everything in JIT. For
demonstration, that’s fine. So:
- At program load, after generating bytecode, VM can call
jitCompiler to compile all functions (except maybe some trivial).
- Then when running,
interpreter can be bypassed entirely and we just call main compiled function. But since
assignment says JIT, likely they expect the program still runs via VM logic, just that JIT is
integrated. But an alternative approach: After compile, skip interpreter and just call
compiled code for main, treating interpreter as fallback. But to keep GC integration and
such, maybe we still run interpreter but for heavy parts use compiled segments.
- However, due to time, baseline compile-all is acceptable and easier for plan. Let's
assume baseline compile-all functions once the parser & codegen done. But we'll still
integrate in CALL logic in case not compiled.



---


## Страница 21


Разработчик интерпретатора подготавливает возможность как compile-on-call:
adds boolean flag to VM like enableJIT. If true, then on first CALL, do compile.
Alternatively, as said, might call compile for all in advance (like ahead-of-time using JIT
component). Результат дня: Код интерпретатора адаптирован: присутствует
структура хранения скомпилированных функций, и при вызовах (или start) он
взаимодействует с JIT. Пока, JIT компонент может быть заглушкой (например,
возвращает null or throws "not implemented"), но интерфейс готов. 1. День 7:
Совместное тестирование и оптимизация VM + JIT + GC. К этому моменту
разработчик JIT должен предоставить работающий компилятор для хотя бы части
инструкций. Интерпретатор начинает вызывать его и реально исполнять
скомпилированный код. 2. Первый тест: небольшая функция (например, sum, или
factorial(5)) компилируется и вызывается. Проверяется, что результат совпадает с
интерпретатором. Очень вероятно, выявятся баги: например, неправильно
передаются аргументы, или JIT-код не взаимодействует с VM как ожидалось. 3.
Отладка: и интерпретатор, и JIT-разработчики вместе смотрят, где рассинхрон.
Например, JIT сгенерировал код, который ожидает параметры в регистрах, а мы не
подготовили. Может потребоваться адаптация:
- Решают, что перед вызовом
скомпилированной функции интерпретатор подготовит аргументы на стеке
процессора. Если JIT нацелился на x64, то первые 6 arguments – в регистрах (RDI,
RSI, etc), или maybe easier: push them on native stack and do a call.
- Более простой
вариант: JIT-компилированная функция сама обращается к структурам VM (like
uses a known static reference to VM and knows offset of stack array, etc.). Тогда VM just
calls it with no args (or passes pointer to VM as arg), and compiled code manipulates
VM->stack. For example, pass this (VM instance) to compiled code, and compiled code
uses it to access VM.stack and do operations – basically replicating interpreter in native.
This is plausible: treat compiled function as specialized version of interpreter loop for
that function, in native code.
- injuly blog suggests similar: mapping opcodes to machine
instructions, and compiled block still accesses VM structures 10 11. We can follow that:
compiled code will directly manipulate VM's stack memory, etc., thus consistent with
interpreter. 4. Допустим, выбрали: compiled function signature func compiledFun(vm:
VM) returns Long (result). Then VM calls it via JNI or MethodHandle, passing its instance.
Compiled code knows offsets of vm.stack, vm.stackPointer, etc. That was set by JIT
codegen. This avoids messing with high-level call conventions for each var. 5.
Interпретатор developer helps adjust call: using e.g. MethodHandles.Lookup to call
pointer. Possibly uses JvmStatics or something as needed. 6. Сборщик мусора:
возможно, Role4 готов с mark-sweep. Интерпретатор должен интегрировать:
- Provide roots: e.g., implement in VM a method gatherRoots(): List that collects all
references from operand stack (all values that are >=0 and < heap.size maybe, if we
encode references as int indexes and other ints as maybe negative or huge? Actually, we
might not differentiate type of stack content easily. Option: make all objects



---


## Страница 22


in heap have index >= some offset to distinguish. Simpler: maintain separate stack for
references or a bitmap parallel to stack marking which slots are refs. Alternatively, store
objects as negative numbers? But if ints allowed negative, cannot. Perhaps store all
references as an object type in Kotlin stack? That complicates generics. Another
approach: each HeapObject has unique ID plus also keep track of where on stack it is
referenced... This is design heavy. But to not digress, we assume we can identify
references by either type info (like separate opcodes or context know that arr operations
produce references).
- Given short time, possibly treat everything on stack as potential
reference (conservative approach). But better: define that any value that corresponds to
an object reference is wrapped in a Kotlin object type (like an ObjectRef class with an id).
Then stack can be of type Any, containing either Long or ObjectRef. But that’s heavy for
interpreter speed. Possibly not needed with proper discipline.
- Perhaps simpler: since
our only objects are arrays and we always handle them via specific instructions, the
interpreter knows at runtime if a stack value is an array reference because it came from
ALLOC_ARR or LOAD_ARR (which pushes normal int). Actually, ALLOC_ARR pushes
reference (should mark it as such). Could maintain a separate boolean stack for "isRef"
flags parallel to values stack. That is easier: pushRef(x) vs pushVal(x). Implement that
quickly. Then GC can scan stack and if isRef[i] true, treat stack[i] as heap index.
- Implement mark phase: from each root (global vars in globals too, they might store
references), mark reachable by DFS: arrays might contain references to other objects if
we had composite, but we have only int arrays of primitives, so no internal references to
mark. So just mark directly roots. Sweep: go through heap list, free those not marked
(here free = remove from list or mark available; careful if remove changes indices of
others – better mark freed but keep placeholder).
- Possibly simpler: do not actually
compact heap, just mark freed objects so their indices won't be reused (fragmentation
but fine).
- Developer integrates GC such that it stops VM loop: the call GC.collect() likely
runs its own loop, but since single-threaded, it's fine. Just ensure that while GC runs, no
VM operations. 7. Интерпретатор разработчик вместе с GC-разработчиком
тестируют GC: allocate a few objects, drop references, call GC, see if freed. They may
add logging: e.g. before and after sizes. 8. Test prime generation with GC: in primes,
after sieve array allocated, many objects are not allocated subsequently, so GC isn't
heavily used (just one big array). Perhaps write another test that alloc lots of arrays and
releases references (like in a loop for i in 1..100 { arr = new IntArray(1000); arr = null; }
– to simulate garbage). 9. Adjust any integration issues (like if GC needs stop-the-world,
ensure interpreter yields).



---


## Страница 23


Результат дня: Получена работающая сборка мусора (в интеграции) 12, JIT
вызывается и по крайней мере не нарушает работу (даже если performance gain
minimal at this point). Интерпретатор код теперь финально содержит все связи. 1.
День 8: Финальное тестирование производительности и корректности. Этот день
посвящен проверке, что с JIT и GC включёнными, система выдаёт корректные
результаты и ускоряет тяжелые задачи: 2. С JIT: выполнить сортировку 10k и
решето 100k, замерить время с JIT и без. Ожидается ускорение (может быть
значительное, если JIT генерирует оптимальный код). Если ускорение не
наблюдается или код падает, профилируют:
- Возможно, JIT сгенерировал
неэффективно, или overhead вызовов. Пытаются оптимизировать: например, если
видят, что вызов JIT через JNI слишком долгий, могут решить: компилировать весь
main-loop. Но это уже запоздало. Скорее, если JIT не успевает быть эффективным,
уменьшают масштабы демо (например, сортировать 1000 вместо 10000, хотя
лучше, чтобы JIT дал эффект).
- Проверяют, что рекурсивный factorial тоже
работает с JIT (возможно, factorial was compiled and calls itself compiled). 3. С GC:
проверяют, что при длительных циклах или множестве объектов, GC срабатывает
и не ломает программу. Например, можно принудительно сделать heap threshold
низким (например, каждые 10 выделений) и видеть, что GC.collect() вызывается
много раз и программа всё равно верна. Желательно убедиться, что GC не удаляет
нужные объекты: тест, где массив используется после нескольких циклов, и GC
запускался – массив всё еще там, не freed. То есть, проверка, что метки root верны.
4. Тест на утечки: запускают код, который должен освобождать память (если GC
работает, heap не будет неограниченно расти). 5. Корректность: все результаты
совпадают с ожиданиями. По итогам, делаются последние оптимизации: -
Например, интерпретатор может поддерживать trace logging опционально (по
флагу) – печатать выполняемые инструкции (для отладки). По умолчанию
выключено, но для разработчиков полезно. - Обрабатываются граничные случаи:
если пользовательский код делит на 0, интерпретатор мог бы кидать ошибку
(сейчас у нас DIV просто выполнит Kotlin / на Int, что кинет ArithmeticException –
можно перехватить и превратить в понятное сообщение на нашем уровне). - Если
выход за пределы массива – сейчас LOAD_ARR/STORE_ARR можно проверить и
кинуть ошибку "Index out of bounds in array". - Если стек переполнен (глубокая
рекурсия) – можно отлавливать и говорить "Stack overflow". - Эти проверки
добавляются, чтобы VM не крэшилась без пояснений. 1. День 9: Рефакторинг,
оптимизация и подготовка к сдаче. Разработчик интерпретатора приводит код в
чистый вид: 2. Разбивает длинные функции (например, run() можно разделить на
несколько методов: executeInstruction(opcode) чтобы упростить читаемость). 3.
Добавляет комментарии около нетривиальных мест (например, объясняет логику
CALL/ RET, отмечает, что ref-ы на heap хранятся как int, указатель на heap). 4.
Убеждается, что все debug-логгеры выключены или переключаются опцией. 5.
Проводит код-ревью с другим разработчиком: может, JIT-разработчик смотрит,
насколько понятно интегрироваться, или парсер-разработчик смотрит, все ли
семантические моменты соблюдены (например, интерпретатор действительно
сначала вычисляет условие, потом ветку – без перепутывания). 6. Документирует
использование VM: описывает, как вызывать виртуальную машину, какие методы
главные. Скорее всего, есть фасад: MyLang.execute(programFile) внутри делает
parse->generate->vm.run. Это можно описать в README.



---


## Страница 24


7. Проверяет модульные тесты: если были (можно написать несколько unit-тестов:
push/pop, simple arithmetic, call, recursion, array access). Они должны проходить. 8.
Производительность: если осталось время, попытка улучшить интерпретатор, хотя
фокус JIT. Но можно: использовать массив примитивов вместо коллекций
(например, IntArray for stack for speed). Kotlin/JVM will use bounds check but it's ok. 9.
GC: проверить, что нет stop-the-world слишком долгого (в наших размерах не
заметно). Результат: Интерпретатор/VM модуль полностью готов, с хорошо
структурированным, понятным кодом, соответствующим спецификации. 1. День
10: Финальный цикл тестирования и документации. Собрать всю систему в целое
(возможно, в репозитории проекта настроены gradle модули для parser, language,
vm, jit – интеграционный проект). Разработчик интерпретатора инициирует
финальный прогоны:
- Запуск всех трех демонстрационных программ через CLI,
получение результатов/ времени, фиксирование их.
- Возможна запись скринкаста
или логов выполнения для заказчика, например: $ mylang factorial.my Result:
2432902008176640000 (computed in 0.002 sec) $ mylang sort.my prints sorted and
maybe time, etc.
- Последние исправления, если вдруг что-то всплыло (например,
JIT fails on one specific pattern, maybe fallback to interpreter for that). Документация:
пишет раздел о устройстве виртуальной машины: - Как работает интерпретация
(описать, что наш VM – стековый, выполняет инструкции байткода, аналогично JVM
байткоду или Lua VM, приводя аналогии). - Как устроены фреймы вызовов, стек,
куча – возможно, схему или текстовое описание, как вызов функции приводит к
созданию нового фрейма, возвращение – его снятию. - Как отслеживаются
объекты и запускается GC (упомянуть, что реализован алгоритм Mark-Sweep:
пометка достижимых объектов от корней (стек, глобалы), затем очистка
unreachable 12 ). - Как работает JIT: например, "При первом обращении к функции
интерпретатор передаёт её байткод JIT-компилятору, который генерирует
машинный код x86_64, устраняя расходы на интерпретацию циклом switch 10. В
дальнейшем вызовы этой функции выполняются напрямую в сгенерированном
коде, минуя интерпретатор, что ускоряет выполнение." Можно указать, что JIT
реализован по базовому принципу, без сложных оптимизаций времени
выполнения, но даёт выигрыш на больших циклах. - Добавляет инструкцию по
использованию: например, "Для включения/отключения JIT можно использовать
опцию -- no-jit" (если сделали). - Known limitations: напомнить, что это прототип,
например, не поддерживаются строки или float, и т.д. Совместно со всеми
проверяет, что документация проекта полная. После этого – готовится сдача. 2.
Репозиторий/папка: vm (содержит реализацию VirtualMachine.kt, Memory
management, возможно GC interface, и интеграцию с JIT).



---


## Страница 25


3. Зависимости: использует модуль байткода/спецификации (Role1) для понимания
инструкций; получает на вход сгенерированный байткод от связки Role1+Role2;
взаимодействует с JIT/GC модулем (Role4) для ускорения и памяти. 4. Ключевые
контрольные точки: 5. Базовый цикл интерпретатора с арифметикой работает
(день 2). 6. Вызовы функций и рекурсия работают (день 3, тест factorial). 7. Работа
с памятью и объектами (день 4). 8. Интеграция со сборщиком мусора (день 5–6,
готовность механизма). 9. Интеграция с JIT (день 6–7, вызов скомпилированного
кода). 10. Тестирование всех демо-программ на интерпретаторе (без JIT, день 5) и
с JIT (день 8). 11. Промежуточные форматы: Байткод – основной формат
исполнения (в виде структур в памяти). Данные времени выполнения: стек
операндов, стек вызовов, куча – поддерживаются внутри VM. При JIT появляется и
машинный код (хранится, например, в виде скомпилированных функций в памяти).
Управление переходом от байткода к машинному коду – за счёт таблицы
скомпилированных функций, связанной с байткодом функций.
Разработчик JIT-компилятора и сборщика мусора
Роль и зона ответственности: Этот участник отвечает за два взаимосвязанных, но
разных компонента: JIT-компилятор (Just-In-Time) и сборщик мусора (GC).
JIT-компилятор должен брать "горячий" байткод (или функции) и переводить его в
машинный код во время выполнения, повышая скорость выполнения программ 9.
Сборщик мусора автоматизирует управление памятью, освобождая объекты, на
которые уже нет ссылок, чтобы предотвратить утечки памяти. Оба компонента
пишутся на Kotlin (при необходимости с использованием низкоуровневых
возможностей через JNI/Unsafe). Код хранится в модуле jit_gc (либо два связанных
модуля). Зависимости и интеграция: JIT-компилятор зависит от формата байткода
(знать, как
НОВОЕ: Архитектура асинхронного JIT
В дополнение к стратегии «compile-on-first-call» вводится асинхронный
JIT-пайплайн:
- компиляция выполняется в отдельных потоках (корутины),
- VM остается однопоточной: compiled-код исполняется только в потоке VM,
- входные данные JIT должны быть immutable (байткод, константы,
сигнатуры),
- протокол с GC (stop-the-world): фоновые задачи не трогают heap/roots,
- при ошибке ставим FAILED и навсегда используем интерпретатор.
интерпретировать последовательность инструкций) и от структуры виртуальной
машины (для вызова скомпилированного кода, доступа к данным). Он тесно
интегрируется с интерпретатором: VM будет вызывать JIT для компиляции
функций и, наоборот, JIT-сгенерированный код должен вызывать сервисы VM
(например, для аллокации памяти, вызова нескомпилированных функций или
взаимодействия с GC). Сборщик мусора интегрируется с системой управления
памятью VM: VM предоставляет ему информацию о распределённых объектах и о
корневых ссылках, а GC должен уметь приостановить исполнение и очистить
неиспользуемые объекты. Основные синхронизации: - Определение интерфейсов
вызова JIT из VM (к началу разработки JIT). - Согласование стратегии компиляции
(какие функции/когда компилировать). - Определение алгоритма GC и моментов
вызова (середина проекта). - Интеграция: JIT встраивается в VM (примерно вторая
половина), GC – ближе к концу первой недели. - Тестирование полного цикла:
ближе к концу проекта, совместно с интерпретатором. Ежедневные задачи: 1.



---


## Страница 26


День 1:Исследование и планирование JIT-компиляции. Разработчик изучает
спецификацию байткода, предложенную Role1, и логику интерпретатора Role3.
Цель – понять, как переводить наш байткод в машинные инструкции x86-64
(подразумеваем, что целевая платформа – десктоп, Linux/Windows x64). Выбор:
использовать ли существующие библиотеки. Например, можно рассмотреть
использование ASM (для генерации JVM- байткода), что автоматически даст JIT
через JVM 9. Но т.к. задача – своя VM, вероятнее предполагается прямой
машинный код. Есть вариант использовать LLVM (генерировать IR



---


## Страница 27


и использовать LLVM JIT), но интеграция LLVM займет лишнее время. Поэтому
решено писать собственный простейший кодогенератор на низком уровне. Задачи
исследований: - Ознакомиться с системным вызовом mmap для выделения
исполняемой памяти (придётся через JNI или JNA, т.к. с Kotlin на уровне JVM нужна
нативная помощь). Либо узнать, как в Java пометить ByteBuffer как исполняемый
(есть трюки через Unsafe). - Принять решение: возможно, использовать JNR-FFI или
JNI для генерирования кода: например, генерировать машинный код в массив байт,
затем вызвать через JNI stub. - Составить упрощённый план JIT: он будет
выполняться в несколько шагов 13: 1. Взять байткод функции (список
инструкций). 2. Сгенерировать эквивалентные x86 инструкции, помещающие
результат в регистр (или на стек CPU) и совершающие те же действия. 3.
Завершить сгенерированный код возвратом управления (например, RET). 4.
Сохранить этот машинный код в выделенной памяти и получить указатель на него.
5. Вызывать этот код вместо интерпретатора для функции. - Решить, что
компилируем: вероятно, компилируем целиком функцию (или один цикл).
Выбираем единицу компиляции = функция (соответствует одному блоку байткода)
14. Таким образом, JIT будет работать на уровне функций. - Подготовить шаблон
трансляции: например, для каждой инструкции байткода написать, какие
последовательности x86 она должна дать. - Стековые операции: можно
соптимизировать: например, в интерпретаторе ADD – это pop 2 значения, сложить,
push; в машинном коде можно взять значения, возможно, они хранятся в
регистрах. Но у нас всё в VM.stack, так что подход: сгенерированный код будет
оперировать с тем же VM стеком. То есть, compiled функция будет по-прежнему
пользоваться массивом vm.stack для доступа к переменным и промежуточным
значениям, но избавится от накладных расходов интерпретатора (цикл и условные
переходы) 10 11. - В качестве стратегии: резервировать регистр (скажем, RBX )
под указатель на объект VM (передадим его как аргумент). Тогда, например,
адрес начала массива стека = [RBX + offset] (offset – смещение поля stack в
объекте VM). Аналогично, stackPtr (указатель вершины) = [RBX + offset_sp]. -
Пример: для ADD можем сгенерировать:; assume top of stack index in, say, RSI (or
loaded from VM.stack_ptr - 1) MOV RAX, [RBX + offset_stackPtr]; RAX = sp (index) DEC
RAX; RAX = sp-1 (index of second operand) MOV RCX, [RBX + offset_stack + RAX*8];
RCX = stack[sp-1]; get first operand MOV RDX, [RBX + offset_stack + (RAX-1)*8]; RDX
= stack[sp-2] ADD RDX, RCX; RDX = RDX + RCX MOV [RBX + offset_stack + (RAX-1)*8],
RDX; store result at stack[sp-2] MOV [RBX + offset_stackPtr], RAX; sp = sp-1 (we
popped one) Это реализует pop 2, add, push result. Будет много инструкций, но без
условных переходов. - Конечно, это примитивный JIT (без оптимизации), но уже
устраняет главный overhead – интерпретаторскую диспетчеризацию (switch per
opcode) 10. - Обсуждение с Role3 (VM): нужно узнать смещения полей stack,
stack_ptr, heap и т.п. Вероятно, JIT-разработчик решает зафиксировать эти
смещения либо получая их рефлексией. (Лучше: использовать
Unsafe.objectFieldOffset для VM.stack и VM.stack_ptr). Прописывает как получить эти
offsets в коде (для генерируемых инструкций). - В конце дня составлен подробный
план генерации для основных инструкций (ADD, SUB, CMP, PUSH, POP, LOAD/STORE,
CALL, RET, JMP). Особое внимание CALL/RET: можно из сгенерированного кода
вызывать другие сгенерированные (или интерпретируемые). Чтобы упростить, как
решили с командой: либо компилируются все функции (тогда JIT может
генерировать прямые вызовы на скомпилированные адреса функций, если их
знает), либо мы допускаем вызывать интерпретатор. Последнее сложнее, так что,
вероятно, JIT-



---


## Страница 28


компилятор будет рекурсивно компилировать все вызываемые функции, либо
сгенерирует вызов через общий stub. - План по GC: Параллельно обдумать
сборщик. Решено реализовать трассирующий сборщик mark-and-sweep 12, самый
простой: - Алгоритм: при вызове GC останавливаем мир, проходим по списку heap
объектов, помечаем все как unreachable. Затем от корневых ссылок (стек, globals)
рекурсивно помечаем reachable объекты (у нас объекты не содержат другие
объекты, кроме массивов примитивов – проще, но если бы содержали, надо
рекурсию). После маркировки – проходим heap и все немеченые освобождаем (в
нашем случае, помечаем свободными или удаляем из списка). - Наш GC не двигает
объекты (не компактирующий), просто освобождает, так что references (индексы)
могут стать дырами или можем их перепользовать? Проще не переиспользовать
индексы (метить объект как null), но тогда heap.size растет. Лучше поддержать
free list: можно хранить в HeapObject поле alive, и при аллокации сначала
проверять, есть ли освобожденные слоты (например, keep list of free indices). - В
начале лучше самое простое: не переиспользовать (в 2 недельном проекте рост
heap до пару тысяч не страшен). - Определиться, когда вызывать: по
договоренности с Role3, скажем, каждые N аллокаций. Это настроим потом. -
Подготовить скелет класса GarbageCollector с методом collect(vm: VM). Этот класс
может находиться в модуле jit_gc или в vm, но лучше отдельно. Пока
прописывается, что collect:
fun collect(vm: VirtualMachine) {
// mark phase
vm.heap.forEach { it.marked = false }
// for each root in vm (vm.stack and vm.globals)
// markReachable(rootIndex)
// sweep phase
for(obj in vm.heap) {
if(!obj.marked) free(obj)
} } Реализацию markReachable можно позже дописать. - Совместно с Role3,
определяют, как VM предоставит корни: например, VM может иметь метод
getActiveRefs(): List или vm.stack + vm.stack_ptr to iterate. 1. День
2:Прототипирование JIT: начать писать код, генерирующий простейшие функции в
машинный код. Можно использовать approach: 2. Создать байтовый массив
(ByteBuffer) определенного размера (например, 4096 байт) для кода. 3. Заполнять
его машинными опкодами. 4. В Kotlin нет встроенного assembler, нужно вручную
вставлять opcodes. Поэтому, JIT- разработчик собирает справочник нужных
инструкций x86 с их машинными кодами (например, MOV reg, imm32, ADD reg, reg,
JMP rel32 и т.п.). Можно использовать ресурс Intel/AMD мануалов или опираться на
готовые примеры. Возможно, он использует наработки (например, GitHub jit-tutorial
15 или Nullprogram's JIT article). 5. Для начала решает протестировать вне
контекста VM: сгенерировать машинный код функции "double x" (умножить
аргумент на 2) и вызвать ее. Использует Unsafe:
val unsafe = Unsafe.getUnsafe()
val mem = unsafe.allocateMemory(128)
unsafe.copyMemory(byteArray, 0, null, mem, byteArray.size)



---


## Страница 29


val func =
unsafe.allocateInstance(java.lang.invoke.MethodHandle) // not trivial Actually,
constructing a callable function pointer in Java is tricky. Instead, easier approach:
- Use
JNI: Write a small C function that takes a pointer to memory and executes it as function
pointer with an argument. But that introduces building native code, maybe not desirable
in 2 weeks, but possible if someone knows how.
- Another approach: generate a class
with invoke() using bytecode and define it with Unsafe.defineAnonymousClass or
something. But that still runs under JVM, not native. Possibly skip, try simpler:
- There's a
known trick: in Java, to call machine code you allocate memory, but to jump to it you
must use a native method. Perhaps easier: Use sun.misc.Unsafe.invokeCleaner? Or
generate a JNI stub each time? Not ideal. 6. Considering time, maybe JIT dev decides to
compile to JVM bytecode as an alternative approach. e.g., input language -> we could
generate a dynamic Java class that implements the function logic, then load it. This
leverages the JVM JIT and satisfies requirement of JIT compilation (though not at native,
but just-in-time into JVM). It's a valid strategy especially given constraints. 7. Evaluate
that: We have AST/bytecode, we can map it to Java bytecode via ASM library. For
example, take our factorial function, generate Java bytecode that does same logic in a
static method, then load via custom ClassLoader. Then call that method. The JVM will
compile it if it's hot. This avoids unsafe. 8. But it might be considered cheating since it's
not our own JIT. The question explicitly says "собственная виртуальная машина... и
JIT-компиляция". Possibly they want our own JIT. We'll assume continuing with native
approach. 9. JIT-разработчик пробует generating a simple machine code sequence:
- Example: function that returns constant 42. x86_64: B8 2A 00 00 00; MOV EAX, 42 C3;
RET (This loads 42 into EAX (the return register for 32-bit int on Windows/Linux x64) and
returns).
- Allocate memory via
ByteBuffer.allocateDirect(16).order(ByteOrder.LITTLE_ENDIAN) and put those bytes.
- Mark memory as executable: on Java 9+ maybe Unsafe has allocateMemory then set
memory page permission. Possibly need to call Unsafe.putAddress? Actually, in JDK not
trivial, likely need JNI call to mprotect. If not, an alternative hack: use
sun.misc.Unsafe.defineAnonymousClass with a compiled binary (some do that).
- At
least attempt to call it: we can't directly jump, but maybe if we define a functional
interface and use Unsafe.allocateInstance... not straightforward. Possibly easiest: use
ByteBuffer and MethodHandles combine? Another trick: a library like JNA (Java Native
Access) could call a function pointer if given one. JNA has a callback mechanism, but
going opposite direction is not direct.



---


## Страница 30


10. Given the complexity, let's propose using the Java Bytecode JIT approach for actual
implementation, but mention in plan the conceptual mapping to machine code. We can
say: "We consider two approaches – direct x86 and generating JVM bytecode. Due to
time, we use dynamic generation of JVM bytecode via ASM to leverage the JVM's own JIT
9." 11. So tasks:
- Import ASM library in build.
- Write code to generate a class like
CompiledFuncN with a static method run(VirtualMachine vm) that replicates the
function's logic. E.g., for each bytecode instruction, emit corresponding JVM instructions:
- Since our VM is in Java memory, maybe simpler: the generated method will simply
contain a Java loop performing same steps as interpreter but with direct operations. That
sounds like just reimplementing interpreter in generated form – which still yields some
speed-up thanks to JIT (no interpretation overhead).
- But we can do even better:
incorporate constants and remove branching. Essentially unroll the function's operations
in straight-line code or with native Java branching for our if constructs, etc. This is like
ahead-of-time compilation to Java.
- For example, factorial function's AST we can
translate to Java method: static long fact(long n) { if(n<=1) return 1; else return n *
fact(n-1); } and compile it. But since we want general, do at bytecode level: not trivial to
handle loops (maybe generate a Java loop corresponding to a bytecode loop).
- Actually,
could do simpler: convert our AST to Java AST or directly to string Java code, then
compile with javax.tools.JavaCompiler at runtime. That is possible but heavy. ASM is
lower level but no simpler logically, just no external process.
- Considering time, maybe
not implement full. But the plan could outline that as fallback approach. 12. For now,
assume we proceed with lower-level JIT (some integration with Unsafe). 13. JIT-dev
implements a minimal function call: likely uses Unsafe.getUnsafe() (accessible via
reflection because normally it's protected). Or uses VarHandle in Java 9, but not for
executing code. 14. Let's say after exploring, the developer decides to postpone actual
call testing and proceed to implement actual compilation of our language functions,
trusting integration will be done at call time with help from interpreter hooking. 15.
Possibly they decide to incorporate an existing tiny assembler library to ease instruction
encoding (if any available for Kotlin). 16. Anyway, Day 2: produce initial code for JIT:
- Class JITCompiler with method compileFunction(funcIndex): CompiledFunction.
- CompiledFunction could be an interface with method execute(VM): Long which either
wraps a MethodHandle to machine code or is a generated class.
- They implement
partial generation: just handle a few opcodes (ADD, SUB, PUSH, etc) to test pipeline.
- Work with Role3 to integrate: stub out CompiledFunction as something trivial first (like it
uses interpreter or returns constant) to allow testing integration without actual code.



---


## Страница 31


17. День 3: Реализация трансляции основных инструкций в JIT. JIT-разработчик
теперь фокусируется на покрытии всего байткода трансляцией: 18. Обходит
инструкции функции и генерирует соответствующие машинные/байткод
последовательности. Подробно:
- Arithmetic and logic: ADD, SUB, MUL, DIV, CMP –
реализовать как прямые машинные операции. Если компиляция на уровне
VM.stack, как обсуждали, то сгенерировать sequence as earlier (pull values from
VM.stack memory via RBX base reg). Это verbose, но mechanizable.
- Jumps:
- For JMP
targetIndex: we need to map bytecode indices to machine code offsets. Decide to
implement in two passes: first pass – calculate size of machine code for each bytecode,
to know offsets; second pass – emit actual bytes with correct jump distances. Or simpler:
allocate space for jump offset and patch later.
- Use relative jumps (x86 relative 32-bit).
- Keep a map from bytecode index to machine code offset; another from jump
instruction position to target bytecode index for patching.
- Conditional jump (JMP_IF):
need to compare top of stack to 0. That means generate code to load that value (like pop
into a reg), compare reg to 0, then emit a conditional jmp (e.g., JNZ or JZ depending on
convention).
- If we define our JMP_IF as jump if value!= 0, then implement as CMP RDX,
0; JNZ rel32.
- Function call and return: This is tricky:
- If we compile all functions, we
could turn CALL funcIndex into direct call of that other compiled function. But we need its
machine address. Solution: compile in any order, store addresses in a table accessible by
compiler. If doing one by one, might compile callees on the fly or have stub.
- Alternatively, since we allow fallback to interpreter, simplest approach: compiled code
calls back into VM’s interpreter for the call (slower, but maintain correctness). But that
ruins performance for nested calls.
- Possibly, for demonstration, not many nested calls
except factorial. We could accept factorial's recursion goes back to interpreter (this
would not speed factorial).
- For full effect, maybe handle direct recursion by self-call in
compiled code (loop?), but complicated.
- Perhaps a hybrid: do not compile recursive
functions deeply, or if we detect recursion, we allow some recursion depth in compiled
code and then bail? Too complex for plan.
- Instead, let's assume JIT will compile all
functions that are called by compiled code (maybe compile whole call graph of main).
- Implementation: for each CALL funcIndex, if funcIndex has no compiled code yet, pause
current compilation, compile target (or at least get its address), then resume. That’s like
on-the-fly dependency resolution.
- Or do an initial pass: if we decide to compile all up
front, JIT dev could compile all functions sequentially (since we have the list of
functions). That avoids on-the-fly. That might be easier: compile each FunctionCode in
BytecodeModule, store their machine code in an array, then linking calls is easy because
all addresses known.
- Yes, let's do that: when user triggers JIT (maybe at program start
or first call), we compile every function in module. Then fill in call instructions with
correct addresses.
- So JIT dev on Day 3 might implement a loop: for func in
module.functions -> compile to machine code (with stubs for jumps/calls to unknown
addresses, recorded). After all, patch the stubs now knowing addresses.



---


## Страница 32


- There is risk: if one function is recursive, initial compile will generate call stub, after
compile, how to patch a call to itself? But now we have address; yes, if compiled all, we
do know self address by the time patching (since we compile in some order, maybe
factorial appears in list and gets compiled fully including its call which initially maybe put
a placeholder).
- For recursion, a direct call to self by address is fine (it'll call the same
function in machine code, recursion works).
- Implementation: allocate one large buffer
or one per function? Possibly one per function easier for memory management; then
connecting calls might involve moving across buffers (needs absolute addresses or
trampolines).
- Alternative: allocate one contiguous block for all code so relative jumps
can cover any function? Relative 32-bit can jump ±2GB, which is fine for our code sizes.
- Could place functions back-to-back in memory, align etc. Then call can be relative or
absolute. E.g., x86 CALL rel32 uses relative offset. If we know offset difference, can
patch easily.
- So plan: allocate, say, 64KB memory for code. As compiling, fill it. Keep
track of current pointer.
- For each function, record its start offset in that block. Store in
table index->offset.
- When emitting CALL funcIndex, compute relative =
table[funcIndex] - (currentAddr + 5) (since call encodes next instr).
- If target not
compiled yet, store placeholder in patch list to fix later.
- Actually easier: compile in
same order as function indices, so any call with higher index might not compiled yet. But
if call points to forward function, placeholder needed. If call to earlier function, offset
known, fine. If recursion (calls itself), then start offset known (pointing to itself), relative
= 0 (plus overhead), which might need patch after we know exact length? For recursion,
if we're in middle of assembling function and see call to self, we can't finalize offset until
after finishing function (or we could allow self-call by computing relative to start, which is
known, but that doesn't include function prologue or current offset?). Actually, call to
start of same function is allowed (it will restart function).
- It's complicated but can be
handled with patching after assembly. 19. By end of Day 3, JIT dev should have
implemented code generation logic for most instructions (perhaps not fully debugged),
and a scheme for patching jumps and calls. Possibly writes helper functions like
emitMovRegImm(reg, imm), emitAddRegReg(r1, r2), etc., to abstract byte encoding.
20. Meanwhile, GC development Day 3: Implement mark phase:
- The developer writes
method to mark reachable objects:
fun markFromIndex(index: Int) {
if(index < 0 || index >= vm.heap.size) return
val obj = vm.heap[index]
if(obj == null || obj.marked) return
obj.marked = true
// if objects had references inside, traverse them (not needed
for int arrays) } Then for each root reference (obtained by scanning vm.stack up to
vm.stack_ptr and checking flag, plus global variables array), call markFromIndex.



---


## Страница 33


- Sweep: iterate heap, any obj with marked=false and not null => set null (free). If
decided to reuse slots, add index to freelist.
- For now, no compaction, as said.
- The
developer tests GC logic in isolation: e.g., create a dummy VM with some heap objects
and a fake root list, call collect, see if unreferenced get freed. Possibly writes a simple
unit test simulation. But actual integration test after hooking with real VM. 21. День
4:Интеграция JIT с виртуальной машиной (часть 1). 22. До сих пор JIT работал
автономно. Теперь необходимо обеспечить вызов сгенерированного кода из
интерпретатора. 23. Совместно с Role3, решают, как именно это сделать на JVM:
- Возможный путь: использовать java.lang.reflect.MethodHandle. There's
MethodHandles.Lookup.findVirtual if we had a compiled function as a method in some
class. If we had used ASM to generate a class with static method, we could get a
MethodHandle to it and invoke. But with raw memory, no direct reflection.
- Or, use
sun.misc.Unsafe via reflection (since Unsafe is restricted). The developer can obtain an
Unsafe instance by reflection (getting the field "theUnsafe"). Then use allocateMemory
to allocate memory and write code.
- Also, use Unsafe.putLong(address, value) etc to
write machine instructions.
- Mark memory executable: There's no direct in Unsafe.
Possibly call native mprotect. Might have to use JNA:
- Add JNA and do: NativeLibrary lib
= NativeLibrary.getInstance("c"); Function mprotect = lib.getFunction("mprotect");
mprotect.invoke(..., address, length, PROT_READ|PROT_WRITE| PROT_EXEC); But then
the memory was from Unsafe which might not be aligned to page or separate page.
Could allocate entire page via Unsafe.allocateMemory(pageSize) (which is 4096
typically) to ensure page alignment for mprotect.
- If not JNA, could make a small JNI
library just to call mprotect.
- Given time, maybe use JNA for simplicity, it's pure Java
usage.
- Next, how to call that function pointer:
- Possibly by creating a Direct
ByteBuffer and using invokers is not possible. There is a trick: define an interface with
method taking longs, then use Unsafe.defineAnonymousClass to define an
implementation of that interface that simply does a jmp to the function pointer. Actually,
one can craft a machine code that does a tail jump. Some advanced exploitation used in
e.g. JIT frameworks.
- Alternatively, create a JNI function on the fly? Possibly define a
new native function at runtime is not trivial either.
- Another hack: If one is allowed to
use invokedynamic or generate a Lambda that captures a pointer, maybe possible with
MethodHandles. Possibly, in Java 15, there is foreign linker API (Project Panama) that
allows calling function pointers. But let's not assume that.



---


## Страница 34


- For plan, might suffice to say: "We will use Unsafe and mprotect to allocate and invoke
the compiled code" and cite that it's doable as shown in similar JIT tutorials (like Spencer
Tipping's JIT or Kuterdinel's blog) 16. 24. So, integration tasks:
- JIT dev writes a function
makeExecutable(byte[] code): CompiledFuncHandle that:
- Allocates memory with
Unsafe.allocateMemory(len).
- Copies the code bytes in.
- Uses JNA to call mprotect on
that memory region (set exec).
- Wraps the address in a Java object for VM to store.
- Possibly defines CompiledFunction as an interface with a method execute().
- If direct
call not possible, one plan: use ByteBuffer and hoping the JVM doesn't prevent execution
(it will though).
- Could attempt writing to a MappedByteBuffer from a file with
MapMode.EXECUTE if that existed.
- Suppose they succeed in obtaining a long funcPtr.
- Now, how to call it:
- There's no direct in pure Java. But one can use
jdk.internal.misc.Unsafe (maybe same) which had invokeCleaner but no call.
- Possibly,
again JNA: JNA allows define a com.sun.jna.Callback for function pointer to call C code
from Java. But we want opposite: calling a pointer as if function pointer from Java. JNA
library has Function class that can call a function at a given address with a given
signature. Actually, yes: JNA can call function pointers using Function.invokeXXX if we
have an address and signature.
- Alternatively, use LibFFI via JNR. Actually JNR (Java
Native Runtime) might be better: it can create a closure to call native function pointer.
- This might be the easiest: use JNA's Function: Function func =
Function.getFunction(address, Function.ALT_CONVENTION); long result =
func.invokeLong(new Object[]{ arg1, arg2 }); But since our compiled code might expect
a pointer to VM in RCX or something rather than through typical conventions, we need to
align that. Perhaps we should compile with System V AMD64 calling convention so that
first arg (RDI) = pointer to VM, and result in RAX. Then JNA can call it like a C function
with one pointer argument. If JNA uses stdcall vs cdecl, but on x64 it's unified. ▪ Yes, if
we treat compiled function as long func(VM* vm) in C terms, JNA can call it by passing
the VM pointer. That means in code generation, ensure we treat RDI (or RCX depending
on platform, but on SysV Linux, first arg in RDI) as VM*, and maybe in Windows x64, first
arg also RCX. Actually, SysV x64: first arg in RDI. So if we standardize on that, our code
should load RBX from RDI (RBX = VM pointer, used for data). ▪ When calling via JNA, we
need the address and likely specify calling convention as default (which is C (cdecl) for C
on x64? But on x64, cdecl vs stdcall is irrelevant, it's unified fastcall). JNA presumably
uses whatever default calling conv of platform, which matches how we generate code. ▪
The result will be returned in RAX as per C convention (64-bit).



---


## Страница 35


▪ This could work. We'll proceed with that plan.
- So JIT dev ensures compiled code uses
RDI as pointer to VM. At start of each compiled function, maybe push RBP, move RDI to
RBX (so we can use RBX as base throughout), and at end restore RBP and ret (standard
prologue/epilogue).
- Implement calling via JNA Function: It's slow to call through JNA for
each call, but hopefully JIT compiled code itself is fast in loops. Actually, if function itself
contains loop, it's in native code, that’s the big win. The overhead of one JNA call per
function invocation might be acceptable. E.g., sorting: maybe one function with nested
loops, then only one JNA crossing to start, loop executes natively. 25. By end of Day 4,
have:
- Verified we can allocate, write, protect memory for code (maybe tested on a
trivial code piece).
- Verified calling convention alignment (maybe by writing a trivial
function that returns known value and calling via JNA to see if it works).
- Not fully tested
entire compilation, but integrated enough to start testing actual compiled functions in
coming days. 26. GC Day 4: Integrate GC triggers:
- Work with Role3 to incorporate calls
to GarbageCollector.collect in VM code after allocations. Possibly set a threshold.
- If
available, test with actual VM: Write a small program that allocates objects in a loop and
drops them (like a pseudo code using global variable to null out references each
iteration, forcing them unreachable).
- Force GC by lowering threshold (like every
allocation for test).
- Use logs to verify mark-sweep freed something.
- Ensure GC does
not free still used stuff: test with scenario keep reference to one allocated array, null
another, call GC, check that first is still accessible.
- Fix any errors (like if forgetting to
mark a root or double-free).
- Possibly find out that identifying roots from stack is tricky.
If used the parallel boolean stack idea, ensure VM is marking pushRef/pushVal
appropriately in all instructions:
- Role3 should incorporate that. If not, GC developer
might implement a simpler heuristic (like treat any stack value in range [0, heap.size) as
ref - could misidentify an int that equals a valid index as object, which is a conservative
GC approach 17. This is safe (won't free live objects incorrectly, though may keep some
garbage wrongly).
- Considering minimal risk, could do conservative mark: iterate stack
values (which are Longs), if value is within heap index range and object at that index not
null, mark it. This might treat a numeric 5 as a reference to object index 5 erroneously.
But unless our program stores small ints that coincide with object IDs, not critical. But it
could cause memory leak if false positives. However, easier than tracking reference
types precisely, given time.
- If needed, mention implementing a conservative GC to
simplify pointer identification 17.
- Document in code that it's conservative if so. 27.
День 5: Завершение JIT-компилятора. Основная цель – добиться, чтобы JIT мог
полностью скомпилировать все три демонстрационные программы. Подробности:



---


## Страница 36


28. Дописать поддержку всех оставшихся инструкций:
- LOAD/STORE:
сгенерировать машинный код для доступа к локальным переменным. In compiled
code, we might maintain the same approach as interpreter: base pointer plus index. But
we have base in RBX (VM pointer) plus maybe an offset (the base index of locals in
stack). That base index might be known at compile time? Possibly not, since each
function’s base depends on call context. But maybe in compiled code, instead of using
VM.stack at all for locals, use actual CPU registers or stack.
- Alternatively, compiled
code could allocate space on the CPU stack for local variables (like in typical native
code). That would diverge from using VM.stack. But simpler approach: still use VM.stack
for everything to avoid managing two storage models. It means compiled code will rely
on VM.stackPtr during execution which might not move as in interpreter (because in
interpreter calls, pushing/popping cause changes).
- Possibly do: When compiled
function starts, it knows how many locals (including params), and it could set up its own
frame pointer. But mixing that with VM.stack complicates coherence if compiled and
interpreted code intermix.
- Idea: if all functions compiled, we could ditch VM.stack for
them and use native stack. But GC then wouldn't see local references in native stack
easily (though we can register them as roots or not needed if all local references turned
into registers? But GC can't scan CPU regs easily).
- Safer to keep using VM.stack as
source of truth for data.
- So implement LOAD/STORE by same memory operations on
VM.stack array at index (baseIndex + varIndex). But what is baseIndex? ▪ In interpreter,
baseIndex is known only at runtime (call time). We can simulate that by capturing the
base pointer when JIT compiled function is entered. For example, treat RBP as the base
index value. If we pass it in or compute from VM.stack_ptr at call time: ▪ Possibly: before
calling compiled function, interpreter could set a global var in VM like currentBase =
(stack_ptr - numArgs) and pass its address or index. ▪ Or better, when compiled function
is called, it receives as argument current stack index pointer. Actually, our compiled
function signature could be execute(VM vm, long baseIndex). Then two arguments: RDI
= vm, RSI = baseIndex. Then compiled code uses RSI as base offset for locals. ▪ It's
easier to pass base as second arg than to retrieve from VM inside code (since interpreter
knows it). ▪ Yes, modify calling convention for compiled: first arg VM, second arg
baseIndex. Then JNA call needs two parameters. ▪ That should be okay: JNA Function can
take two parameters (Pointer and long). ▪ Then code generation: ▪ At function start,
move RDI (vm pointer) to RBX (base reg). ▪ Put baseIndex value (in RSI on Linux x64 as
second arg) maybe into, say, RBP or keep RSI as is for use. ▪ Then LOAD idx becomes:
MOV RAX, [RBX + offset_stack + (baseIndex+idx)*8]; load value PUSH RAX or move to
stack? Actually, how to handle stack operations in compiled code?



---


## Страница 37


Perhaps compiled code can avoid actual push/pop instructions on CPU stack by tracking
a "VM stack index" in a register. Possibly replicate what interpreter does: ▪ Keep a
register (maybe R12) as current top index relative to base. Initially, R12 = number of
arguments (for a function entry, stack_ptr at call base + args count). ▪ Then a push in
VM terms means increment R12 and store something at [stackBase + R12]. ▪ A pop
means read [stackBase + R12] then decrement R12. ▪ Actually, better track absolute
stack_ptr = baseIndex + something. But we passed baseIndex separately, or it could be
just previous stack_ptr on entry. ▪ Let's say at entry, we pass baseIndex which is start of
this function's frame in VM.stack. If we also pass number of args (or we know from
function signature how many params), we can set initial top = baseIndex + numLocals
(or baseIndex if locals start after arguments? Actually baseIndex itself often points to
first local/arg). ▪ Might be easier: treat baseIndex as current stack_ptr at entry (so it
points right after last argument pushed by caller). Then the first local index = baseIndex
- numArgs. Actually, this is getting too detailed. Possibly skip detail in plan, assume JIT
can manage it by reading some VM field for base and using offset. ▪ For plan's sake, say:
compiled code uses same stack indexing as interpreter, retrieving base and adjusting
index for local variables. ▪ Given complexity, mention that time is short and small
inefficiencies accepted (like compiled code might still use VM.stack like interpreter, but
fewer overheads).
- CALL in compiled code: Since we compiled all functions, call
becomes a direct call instruction to another compiled function's address (which we patch
as discussed).
- Ensure to preserve calling convention: our compiled functions expect
VM and baseIndex, so we must arrange to pass those when calling.
- If calling another
compiled function, in assembly emit: ▪ Load appropriate baseIndex for callee into RSI,
ensure VM pointer in RDI, then CALL rel32 to target. ▪ Base for callee likely = current top
of stack after pushing args minus (args count - 1)? Possibly we compute it similarly to
interpreter: if current R12 is top index offset relative base, then baseIndex for callee =
baseIndex + (currentTopIndex - argsCount + 1). ▪ Might simplify by requiring that before
CALL, arguments are evaluated and left on stack, currentTop = baseIndex +... points to
last arg. Then pass baseIndex for callee = baseIndex (the same)? That wouldn't be
correct if new frame shares same stack. ▪ Actually, in interpreter, all frames share one
big stack. So baseIndex of callee = current global stack_ptr - numArgs. ▪ We can
similarly do: At compiled call, we know how many args N (since from AST or function
signature). We can generate code to compute baseIndex_callee = current global
stack_ptr (which is baseIndex + currentOffset) - N. Because current global stack_ptr =
baseIndex + currentTop. ▪ Possibly get current stack_ptr from VM (vm.stack_ptr field) at
runtime just before call, because interpreter updated it when pushing args. But if
compiled code itself pushed args without updating VM.stack_ptr global ( maybe it should
update that field as it simulates push?), or we could update VM.stack_ptr as compiled
code executes to keep it consistent for mixing with interpreter or GC.



---


## Страница 38


▪ It might be necessary that compiled code continuously updates vm.stack_ptr as it
pushes/pops to maintain consistency for GC and any fallback. ▪ If yes, compiled code
must include instructions to update [RBX + offset_stackPtr] whenever stack changes.
That was in our earlier example for ADD, we did update stackPtr at the end. ▪ So do
similar for calls: ▪ Before pushing args, stackPtr in VM is updated after each push.
Actually, generator likely had already inlined pushes as part of evaluating arguments. ▪
When ready to call: the VM.stack_ptr now points just beyond last arg. ▪ Use that value
minus N as base for callee. ▪ Steps: MOV RAX, [RBX + offset_stackPtr]; get current SP
(end of args) MOV RSI, RAX; RSI will be baseIndex for callee (start of frame at first arg)
CALL rel32; call compiled function ▪ After return, maybe adjust stack (pop args & push
return) but if function put result at last arg position per convention, might just adjust one
slot. ▪ Possibly define that the compiled callee leaves result at same location as first arg
(like how interpreter left result on stack by replacing first arg position). But typical is to
remove args and push result. We can mimic interpreter: in interpreter, after call returns,
the args are gone and one result is pushed in their place. ▪ Could implement in compiled
code by: after call, write result (in RAX perhaps) to [RBX + offset_stack + RAX_idx] and
update stack_ptr accordingly. ▪ Actually, simpler: treat call like black box: compiled
callee will manage its frame and on return, we assume VM.stack_ptr is already popped
back except result. But since compiled uses same global stack, and if compiled callee
left result at stack[baseIndex] of callee, and then returned, how to restore caller's stack
pointer? ▪ Might do: before call, note current SP in a register, after call, restore it minus
(args-1) since one result replaced args. ▪ This is quite complex to get exactly right. But
likely can manage if time.
- Considering time, maybe not all intricacies are solved, but
we plan as much and accept if some calls still fallback. 29. Summarizing Day 5, JIT dev
finalizes code generation for:
- Arithmetic ops, stack ops, control flow, calls/returns.
- Ensures machine code is placed and patched correctly.
- Possibly writes instrumentation
to dump generated bytes for debugging. 30. Start testing piecewise:
- Try compile a
simple loop function and print machine bytes, maybe manually inspect or run if possible.
- Also make sure compiled code doesn't exceed buffer or relative jump limits.



---


## Страница 39


31. GC Day 5: Testing and profiling GC:
- Insert counters to see if GC runs and how long
(maybe negligible with small heap).
- If needed, adjust threshold or algorithm (like if
mark phase too slow for large heap, but our heaps small).
- Write some documentation
for GC logic (for internal).
- Possibly simulate a scenario of heavier usage to ensure GC
correctness and no crash.
- GC is likely stable by now. 32. День 6: Интеграция JIT с
виртуальной машиной (часть 2) и начало системного тестирования. 33. Теперь,
когда JIT-компилятор умеет производить машинный код, пора включить его в
основной цикл. Совместно с Role3:
- На этапе запуска программы, после генерации
байткода, JIT-разработчик может вызвать jitCompiler.compileAll(bytecodeModule)
если выбрана стратегия компилировать всё сразу. Это создаст машинный код для
всех функций. В VM сохраняется таблица адресов/функций.
- Интерпретатор на
CALL проверяет: если enableJIT включён, то идёт не в интерпретируемый процесс, а
вызывает JIT скомпилированную функцию через JNA Function.
- Или более
agressively, VM.run() can directly call compiled main function if exists, but probably keep
interpreter for structure.
- Possibly do as initial integration: let the main dispatch still be
interpreter except when hitting a CALL of a compiled function, then do external call. But
that means inside compiled function it runs entirely native, returns to interpreter at RET.
- Actually, if we compiled all, we could just not use interpreter at all except to launch
main.
- But perhaps keep interpreter for fallback if something fails.
- They implement
the check:
if(jitCompiled[funcIndex]!= null) {
// flush any needed state (none if state is shared?), then:
val result = jitCompiled[funcIndex].invoke(vmPointer,
baseIndex)
// after return, push result onto VM stack manually if not
already in place. continue main loop (skip normal call handling) } else {
// normal call as before
} Where jitCompiled[funcIndex] could be a JNA Function or a wrapper to call one.
- Need
to manage baseIndex: as earlier, interpreter has base of current frame, but in
interpreter, at CALL we are in some frame with a base. Possibly pass that base or
compute new. Actually, interpreter code likely computed new baseIndex = stack_ptr -
numArgs (similar to earlier).
- In interpreter call handling they'd do: push frame with
base=newBase. For compiled, maybe do similarly: the current state (stack_ptr includes
args) is ready, we can call compiled function with baseIndex = newBase (start of args).



---


## Страница 40


- We should maintain interpreter's stack as if it's calling normally (increase stack_ptr to
allocate callee locals if needed or not? Actually in interpreter, it doesn’t pre-allocate
locals, it grows stack as push operations happen).
- Perhaps simpler: pass current
stack_ptr (which points after args) as base (like we did earlier for compiled), because
compiled function might treat that as base (pointing to just after last arg).
- Or pass
newBase = stack_ptr - numArgs, aligning with how compiled uses baseIndex of first arg.
- Decide: pass newBase = stack_ptr - numArgs (so that compiled code sees base at
arg0).
- Then compiled code should ideally on entry set stack_ptr in VM to baseIndex
(since in interpreter, stack_ptr stays at end of args? Actually in interpreter, before call,
stack_ptr is at end of args, then in call it remains same because in new frame we reuse
same stack portion).
- For compiled, maybe align: after pushing args, we do not update
stack_ptr further, pass baseIndex pointing at first arg. If compiled code uses VM.stack
and will push/pop, it should ideally start with vm.stack_ptr = baseIndex (like treating that
as top of new frame).
- So in interpreter, maybe temporarily adjust vm.stack_ptr =
baseIndex for the duration of compiled call, then on return set vm.stack_ptr back plus 1
(for result).
- But if compiled code itself will update vm.stack_ptr as it runs, maybe
better: set vm.stack_ptr to baseIndex at call start (like simulate entering new frame).
- This could be done by interpreter just before call: val base = stack_ptr - argCount;
vm.stack_ptr = base; then call compiled. The compiled function will operate, and
presumably leave stack_ptr at base+1 (one result).
- After return, interpreter sets its
stack_ptr to base+1 as well (which should already be if compiled updated it).
- This
aligns with normal call: normally after call, args removed and result left so stack_ptr =
old base + 1.
- Confirm with example: call factorial(5). ▪ Before call, stack might have...
[5] with stack_ptr old_ptr = base_prev +1 (assuming base_prev was old frame start). ▪
base_new = old_ptr - 1 (since 1 arg). ▪ Set vm.stack_ptr = base_new (so effectively
removing arg? Actually we removed the arg from count perspective, but not physically,
just adjusting pointer). ▪ call compiled factorial, which expects base=base_new and sees
arg at stack[base] (since we didn't remove it physically). ▪ compiled factorial uses that
and returns with result in stack[base] (overwriting maybe? Or if it uses same location to
store result). ▪ compiled sets stack_ptr = base + 1 (one beyond base) upon return. ▪
back in interpreter, we set stack_ptr = base_new + 1 (which matches compiled). ▪ End
result: one value (result) on stack.
- That sounds consistent if implemented carefully.
- They implement these pointer adjustments and carefully test a simple function call
scenario to ensure correct behavior. 34. With integration logic in place, start system
testing on small examples:
- Try a simple function that adds two numbers (to test JIT
call).
- Test recursion at small depth (factorial(5)).
- Possibly skip heavy loops for now
until simpler ones stable.
- Check for any mismatch in stack management, fix
accordingly.



---


## Страница 41


- Likely debug needed: e.g. maybe compiled code not updating stack or an off-by-one in
indices. 35. Meanwhile, GC integration:
- Confirm that compiled code still cooperates
with GC:
- If compiled code uses VM.stack and updates vm.stack_ptr, GC can still find
references on stack (since our conservative marking or flag tracking covers them).
- If
compiled code holds references in CPU registers for a while (like loaded arr reference
into RDX but not stored in VM for some time), those wouldn't be seen by GC if it ran
asynchronously. But our GC runs only at safe points (calls, allocations). Usually while
compiled code running we won't trigger GC unless an allocation in compiled triggers it
(we do have compiled ALLOC_ARR).
- If compiled code triggers ALLOC_ARR, our code
generation likely included calling back to a runtime function for allocation (maybe
directly calling a helper in VM or making a call to a stub).
- Possibly simplest: not compile
ALLOC_ARR, but leave it to call interpreter or a runtime library. But we did compile it by
adding an object to heap and updating pointer. That might call GC if threshold reached:
▪ If threshold reached, compiled code might need to call GC.collect(vm) method. That is
a heavy operation in the middle of native code. Could implement as a call to a helper
function: i.e., compiled code can call a known function pointer (like a C function) that
invokes our GC logic via JNI or so. ▪ Or compiled code could simply call back into
interpreter for GC? Hard. ▪ Perhaps, to avoid complication, set threshold such that GC
not triggered by compiled code during our demos (like threshold big enough so GC only
triggered between runs or small tests). ▪ Or ensure compiled ALLOC will call an exported
function doAlloc(VM *vm, size, &resultRef;) that does actual allocate and possibly
triggers GC. The compiled code would call that as an external function (like linking to a C
function we define). ▪ Given time, maybe skip that detail, assume minimal GC
involvement in compiled context.
- Anyway, likely fine if not fully perfect. 36. Result of
Day 6: Basic integration working: can run some programs with JIT. Possibly factorial and
simple loops show correct results. Sorting and primes might still need performance
tuning or debugging. 37. День 7:Оптимизация и исправление узких мест. 38. Run the
full demo programs with JIT on and off to assess performance and correctness:
- Factorial 20: Should be correct both ways. The overhead of JIT for factorial might not pay
off at n=20 (interpreted fine), but it's test for recursion. If it fails, fix recursion handling
(maybe tail call or so).
- Sorting 10000: This is a big test. Without JIT, might be extremely
slow. With JIT, should be much faster if inner loop compiled. Actually, our compiled code
still uses array accesses and stack overhead, but avoids switch dispatch. Possibly a >10x
improvement, which might make difference between tens of seconds vs a couple
seconds.



---


## Страница 42


- If still slow, maybe our compiled code is not optimized or overhead from JNA calls on
each call if the sort uses function calls? But sorting likely all in one function if
implemented straightforward (like a double nested loop in one function).
- Check if
compiled code handles that heavy nested loops and yields correct result. Validate sorted
output.
- If there's an issue (like maybe jumps didn't patch properly in big loops), debug
that. Possibly discovered e.g. a jump offset overflow if code bigger than 127 bytes and
we used short jump incorrectly.
- Memory usage: sorting uses one array of 10k, fine. GC
not crucial here except once after creation maybe.
- Primes 100k (sieve): That is heavy
on loops and array access as well, similar complexity as sort maybe a bit less. Check
correctness (count primes).
- Performance: 100k sieve interpreted might be quite slow,
compiled should help. See if timing is reasonable (maybe a second or two).
- If compiled
code for nested loops has issues (like an incorrect jump condition), debug.
- Also test
smaller values for ease and trust scaled up works similarly. 39. After verifying
correctness, measure roughly speed:
- Possibly incorporate a simple timer in CLI to
output execution time for with/without JIT.
- Confirm JIT indeed gives a speedup ( it
should, though JNA call overhead for one big function isn't too bad).
- If improvement is
modest or negative, find why:
- Overhead of crossing from interpreter to JIT might
overshadow improvements for small loops. But for large loops, should be fine.
- Maybe
our compiled code still doing heavy memory ops (touching VM.stack each operation),
whereas interpreter had them too plus switch overhead. Possibly JIT is significantly faster
but not as much as native C due to still memory indirection. But any improvement
counts.
- If needed, micro-optimize compiled code generation: ▪ Could keep top-of-stack
in a CPU register to reduce memory accesses per operation. For example, in main loop of
compiled code, instead of reading/writing VM.stack for every operation, do more in
registers. However, given time, likely skip such optimizations. ▪ Or reduce redundant
loads/stores: e.g., our naive code might repeatedly do MOV [stack_ptr] etc even if value
kept in reg across instructions. If we had time, could attempt a local optimization pass
(like expression-level). ▪ But with only a few days left, probably not. 40. This day also
used to fix any integration problems that surfaced under stress:
- E.g., maybe memory
leak if GC not triggered. If found that by now, possibly adjust threshold to test GC
explicitly:
- For instance, after primes, maybe explicitly call GC to free that array (though
not needed as program ends).
- Add command-line flag to force GC run to demonstration
(like --gc triggers a manual collection and shows freed count).
- Multi-thread not
relevant, skip. 41. In sum, by end of Day 7, the JIT+GC developer ensures the system
meets functional requirements and improve any shortcoming in JIT logic to handle the
heavy tasks reliably. Document any known issues if unresolved (like "currently, objects
allocated inside JIT-compiled code might not trigger GC automatically due to
conservative approach"). 42. День 8:Документирование и refactoring JIT/GC.



---


## Страница 43


43. Write technical documentation for the JIT compiler:
- Outline its design: using a
baseline compile-all strategy, stack-based code generation, mapping VM opcodes to
native instructions 10.
- Mention that it eliminates the interpreter loop overhead by
converting sequences of bytecode directly into machine instructions for the same logic
11.
- Provide examples: show a snippet of bytecode and corresponding assembly (for
instance, how a simple addition or loop is translated).
- If possible, include a figure or
table of bytecode vs assembly.
- Describe limitations: e.g., no sophisticated
optimizations like register allocation beyond the basic usage, no inlining, etc. It's
essentially a direct translation.
- Note the complexity of integration on the JVM: mention
the use of Unsafe /JNA to allocate and call code, and that in a production scenario one
might prefer targeting an existing JIT like LLVM or generating JVM bytecode for simplicity
9.
- Summarize performance results from demos (like "with JIT, sorting 10k improved
from X sec to Y sec (Z times faster)"). 44. Document the GC:
- Explain which algorithm
implemented (mark-sweep) 12.
- Note that we postpone GC implementation until core
features were working, as done historically (John McCarthy did similarly for Lisp) 18.
- Describe when GC triggers and how it finds unreachable objects (roots from stack and
global, then mark, then free).
- If any limitations (e.g., not compacting heap, potential
false retention with conservative scanning), mention them. 45. Clean up the code:
- Ensure all unsafe operations are well-commented (like why using JNA and how function
pointers are invoked).
- Possibly abstract platform-specific stuff (though likely assumed
x64 only).
- Remove any leftover debug prints. 46. Possibly create some graphs or logs
for demonstration: not mandatory, but e.g., show that GC freed X objects in scenario Y.
47. Assist in writing user documentation if needed: The end user might not directly
interact with JIT or GC (they're behind scenes), but maybe mention a flag to disable JIT
for debugging. 48. День 9:Buffer / Contingency / Final testing. 49. Use this day as buffer
for any unexpected issues discovered by other team members or final integration:
- E.g.,
if parser changes grammar slightly, ensure JIT still handles new pattern.
- If language
dev decided to add a new instruction last minute (like modulo operator), implement that
in JIT quickly.
- If memory issues (like segmentation faults in JIT code) appear, debug
them. For instance, if compiled code jumps to wrong address or writes out of bounds
(could happen if bug in codegen indices).
- Possibly add a safety: if JIT compiled function
fails (maybe detect via try-catch around JNA call?), fall back to interpreter as backup for
reliability. 50. Run a thorough test battery: not only the 3 demos, but other combination
of features:
- If possible, write a small test suite with assorted code (if time).
- Test
scenario: multiple function calls in sequence, nested ifs, while without else, etc.



---


## Страница 44


51. Performance tuning if any glaring inefficiencies:
- Maybe realize JNA calls every time
a function is called from interpreter is costly if many function calls. Possibly mitigate by
compiling main or loops, etc.
- But likely fine. 52. Team meeting: ensure that JIT/GC
integration doesn't hamper normal function. Possibly test with JIT off as well (should still
work fully). 53. At end of day, the system should be stable and ready. 54. День
10:Release preparation for JIT & GC.
- Ensure that enabling/disabling JIT is easy (maybe
a flag, as mentioned, to run interpreter only for comparison).
- If any memory leaks or
resource leaks (like allocated executable memory not freed on exit), handle those
(maybe free memory on program end via Unsafe.freeMemory).
- Write final
documentation sections:
- Possibly a short user doc on how JIT is used (though
transparent).
- A section in the README or technical report about the architecture: e.g.,
"Our VM initially interprets code, but can invoke a JIT compiler. The JIT compiler
translates the bytecode into native x86-64 code and uses the JVM's ability to call native
code to execute it, thereby speeding up loops and arithmetic by a significant factor 10.
The trade-off is complexity and reliance on low-level system interfaces."
- Summarize
results and future improvements (like one could add more optimizations or target other
architectures).
- Double-check GC documentation clarity. Possibly cite that our approach
is simplistic and there are more advanced GC algorithms (if wanted, mention
generational, etc., but no need).
- Final code review and merge JIT/GC module with main
repository.
- Tag release and create any final build artifacts. 55. Репозиторий/папка:
jit_gc (содержит код JITCompiler.kt, GarbageCollector.kt, native integration
components, documentation). 56. Зависимости: зависит от модуля байткода/AST
(чтобы читать инструкции) и от модуля VM (для доступа к внутренним структурам,
либо через API). Интегрируется с VM через согласованный интерфейс вызовов
скомпилированных функций и запуска GC. 57. Ключевые контрольные точки: 58.
Планирование JIT (день 1) – выбрать подход и убедиться, что VM структуры
позволяют вызов machine code 13. 59. Прототип вызова машинного кода (день 2–3)
– сгенерировать и вызвать простейшую функцию (вернуть константу, сложить
числа). 60. Реализация переводчика байткода -> машинный код (день 3–5) –
покрыть все инструкции. 61. Интеграция с VM и выполнение первых функций (день
6) – запускается скомпилированная функция через интерпретатор 10. 62. Полный
прогон демо с JIT+GC (день 7) – подтверждение ускорения и корректности. 63.
Промежуточные форматы: 64. Исполняемый код (машинный код): двоичный
массив, размещаемый в памяти с флагом исполняемости. Каждой функции
соответствует блок машинного кода; хранится адрес начала. Этот код – итог
JIT-компиляции, вызываемый через bridging (JNA/Unsafe) как обычная функция.



---


## Страница 45


65. Таблица скомпилированных функций: структура в VM, сопоставляющая индекс
функции и указатель на её native-реализацию, используется интерпретатором при
вызове функций. 66. Данные для связывания: в процессе генерации JIT хранит
таблицы соответствия адресов для корректировки переходов (jump/call patching).
67. Внутренние структуры GC: отметки объектов (бит marked ), список heap
объектов, возможно, список свободных индексов. GC проходит по графу объектов
от корней (стек, глобалы) и помечает их 19 12, затем освобождает остальные. 1 2
4 5 7 Building Languages on a budget using Kotlin
https://modeling-languages.com/building-languages-kotlin/ 3 8 13 JIT compiler from
scratch – 1/3 https://injuly.in/blog/jit-01/index.html 6 9 Notes on Designing and
Implementing a Small Language
https://colinsblog.net/2022-06-12-notes-on-designing-a-language/ 10 11 14 JIT compiler
from scratch – 3/3 https://injuly.in/blog/jit-03/index.html 12 17 18 19 Garbage Collection ·
Crafting Interpreters https://craftinginterpreters.com/garbage-collection.html 15
spencertipping/jit-tutorial: How to write a very simple JIT compiler
https://github.com/spencertipping/jit-tutorial 16 Writing a very simple JIT Compiler in
about 1000 lines of C
https://kuterdinel.com/writing-a-very-simple-jit-compiler-in-about-1000-lines-of-c.html



---


## Страница 46


Приложение A. Асинхронный JIT - контракты и
примеры
Этот раздел фиксирует изменения архитектуры при добавлении фоновой
(асинхронной) компиляции.
НОВОЕ: Принципы безопасности
1) Генерация/линковка кода в фоне, исполнение - только в потоке VM.
2) JIT-компилятор читает только неизменяемые структуры (байткод, таблица
констант).
3) Любой доступ к heap/stack выполняется только внутри execute(vm).
4) Ошибка компиляции не должна ломать выполнение: fallback обязателен.
Рекомендуемые структуры данных
- jitJobs: ConcurrentHashMap> - задачи компиляции (дедупликация).
- jitCompiled:
AtomicReferenceArray - опубликованные результаты.
- jitFailed: BooleanArray/BitSet -
пометка failed (или хранить state enum).
Псевдокод CALL
fun call(funcIndex: Int) {
val compiled = jitCompiled.get(funcIndex)
if (compiled!= null) {
return compiled.execute(vm)
}
if (!jitFailed[funcIndex]) {
jitJobs.computeIfAbsent(funcIndex) {
scope.async(Dispatchers.Default) { jit.compile(funcIndex) }.also { job ->
job.invokeOnCompletion { err ->
if (err == null) jitCompiled.set(funcIndex, job.getCompleted())
else jitFailed[funcIndex] = true
}
}
}
}
// fallback while compiling (or if failed)
interpretCall(funcIndex)
}
Замечание: публикацию результата можно перенести в поток VM через очередь
событий, если не хотите писать в AtomicReference из фонового потока.